{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "executionInfo": {
     "elapsed": 26892,
     "status": "ok",
     "timestamp": 1744405826453,
     "user": {
      "displayName": "Harshit Singh",
      "userId": "00023943354994433821"
     },
     "user_tz": 300
    },
    "id": "k4K0WdS4vPQq",
    "outputId": "84da3864-7de7-4f79-c366-e1a7ebb0c52d"
   },
   "outputs": [],
   "source": [
    "#pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6176,
     "status": "ok",
     "timestamp": 1744405842082,
     "user": {
      "displayName": "Harshit Singh",
      "userId": "00023943354994433821"
     },
     "user_tz": 300
    },
    "id": "HYNDv_PavTmW",
    "outputId": "66eead86-7321-4c18-9f9a-aac87e932000"
   },
   "outputs": [],
   "source": [
    "#pip install pandas==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2820,
     "status": "ok",
     "timestamp": 1744405864133,
     "user": {
      "displayName": "Harshit Singh",
      "userId": "00023943354994433821"
     },
     "user_tz": 300
    },
    "id": "OBpJWl1-vXqo",
    "outputId": "7086fe50-f408-4dd8-f166-fa8237ccf72c"
   },
   "outputs": [],
   "source": [
    "#pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17256,
     "status": "ok",
     "timestamp": 1744405884686,
     "user": {
      "displayName": "Harshit Singh",
      "userId": "00023943354994433821"
     },
     "user_tz": 300
    },
    "id": "ggbMYh49vYfc",
    "outputId": "f89a5863-a4ab-4f97-c856-7842777e7216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2816,
     "status": "ok",
     "timestamp": 1744405994899,
     "user": {
      "displayName": "Harshit Singh",
      "userId": "00023943354994433821"
     },
     "user_tz": 300
    },
    "id": "vT9LcXRjvfve",
    "outputId": "86a30c00-21b8-4e2c-dd58-80af9fc443e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: distributed in c:\\programdata\\anaconda3\\lib\\site-packages (2024.8.2)\n",
      "Requirement already satisfied: click>=8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (3.0.0)\n",
      "Requirement already satisfied: dask==2024.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (2024.8.2)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (3.1.4)\n",
      "Requirement already satisfied: locket>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (1.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (24.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (5.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (6.0.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (1.7.0)\n",
      "Requirement already satisfied: toolz>=0.11.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (0.12.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (6.4.1)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (2.2.3)\n",
      "Requirement already satisfied: zict>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from distributed) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask==2024.8.2->distributed) (2024.6.1)\n",
      "Requirement already satisfied: partd>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask==2024.8.2->distributed) (1.4.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=8.0->distributed) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2>=2.10.3->distributed) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: numpy\n",
      "Version: 1.26.4\n",
      "Summary: Fundamental package for array computing in Python\n",
      "Home-page: https://numpy.org\n",
      "Author: Travis E. Oliphant et al.\n",
      "Author-email: \n",
      "License: Copyright (c) 2005-2023, NumPy Developers.\n",
      "All rights reserved.\n",
      "\n",
      "Redistribution and use in source and binary forms, with or without\n",
      "modification, are permitted provided that the following conditions are\n",
      "met:\n",
      "\n",
      "    * Redistributions of source code must retain the above copyright\n",
      "       notice, this list of conditions and the following disclaimer.\n",
      "\n",
      "    * Redistributions in binary form must reproduce the above\n",
      "       copyright notice, this list of conditions and the following\n",
      "       disclaimer in the documentation and/or other materials provided\n",
      "       with the distribution.\n",
      "\n",
      "    * Neither the name of the NumPy Developers nor the names of any\n",
      "       contributors may be used to endorse or promote products derived\n",
      "       from this software without specific prior written permission.\n",
      "\n",
      "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n",
      "\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n",
      "LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n",
      "A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n",
      "OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n",
      "SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n",
      "LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n",
      "DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n",
      "THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
      "(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
      "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "Location: C:\\ProgramData\\anaconda3\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: altair, astropy, bokeh, Bottleneck, contourpy, datashader, gensim, h5py, holoviews, hvplot, imagecodecs, imageio, imbalanced-learn, matplotlib, mkl_fft, mkl_random, numba, numexpr, pandas, patsy, pydeck, pyerfa, PyWavelets, scikit-image, scikit-learn, scipy, seaborn, statsmodels, streamlit, tables, tifffile, xarray, xgboost\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>...</th>\n",
       "      <th>Roundabout</th>\n",
       "      <th>Station</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 05:46:00</td>\n",
       "      <td>2016-02-08 11:00:00</td>\n",
       "      <td>39.865147</td>\n",
       "      <td>-84.058723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-2</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:07:59</td>\n",
       "      <td>2016-02-08 06:37:59</td>\n",
       "      <td>39.928059</td>\n",
       "      <td>-82.831184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-3</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:49:27</td>\n",
       "      <td>2016-02-08 07:19:27</td>\n",
       "      <td>39.063148</td>\n",
       "      <td>-84.032608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-4</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 07:23:34</td>\n",
       "      <td>2016-02-08 07:53:34</td>\n",
       "      <td>39.747753</td>\n",
       "      <td>-84.205582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-5</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 07:39:07</td>\n",
       "      <td>2016-02-08 08:09:07</td>\n",
       "      <td>39.627781</td>\n",
       "      <td>-84.188354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID   Source  Severity           Start_Time             End_Time  \\\n",
       "0  A-1  Source2         3  2016-02-08 05:46:00  2016-02-08 11:00:00   \n",
       "1  A-2  Source2         2  2016-02-08 06:07:59  2016-02-08 06:37:59   \n",
       "2  A-3  Source2         2  2016-02-08 06:49:27  2016-02-08 07:19:27   \n",
       "3  A-4  Source2         3  2016-02-08 07:23:34  2016-02-08 07:53:34   \n",
       "4  A-5  Source2         2  2016-02-08 07:39:07  2016-02-08 08:09:07   \n",
       "\n",
       "   Start_Lat  Start_Lng  End_Lat  End_Lng  Distance(mi)  ... Roundabout  \\\n",
       "0  39.865147 -84.058723      NaN      NaN          0.01  ...      False   \n",
       "1  39.928059 -82.831184      NaN      NaN          0.01  ...      False   \n",
       "2  39.063148 -84.032608      NaN      NaN          0.01  ...      False   \n",
       "3  39.747753 -84.205582      NaN      NaN          0.01  ...      False   \n",
       "4  39.627781 -84.188354      NaN      NaN          0.01  ...      False   \n",
       "\n",
       "  Station   Stop Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset  \\\n",
       "0   False  False           False          False        False          Night   \n",
       "1   False  False           False          False        False          Night   \n",
       "2   False  False           False           True        False          Night   \n",
       "3   False  False           False          False        False          Night   \n",
       "4   False  False           False           True        False            Day   \n",
       "\n",
       "  Civil_Twilight Nautical_Twilight Astronomical_Twilight  \n",
       "0          Night             Night                 Night  \n",
       "1          Night             Night                   Day  \n",
       "2          Night               Day                   Day  \n",
       "3            Day               Day                   Day  \n",
       "4            Day               Day                   Day  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# Ignore specific warning category\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "#import dask.dataframe as dd\n",
    "\n",
    "#print(os.getcwd())\n",
    "df = pd.read_csv(r\"C:\\Users\\manoj\\Downloads\\US_Accidents_March23.csv\\US_Accidents_March23.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated DataFrame Schema:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7728394 entries, 0 to 7728393\n",
      "Columns: 242 entries, Severity to Wind_Direction_West\n",
      "dtypes: bool(216), float64(12), int32(13), int64(1)\n",
      "memory usage: 2.7 GB\n",
      "None\n",
      "\n",
      "Missing Values After Handling:\n",
      "Severity                   0\n",
      "Start_Time                 0\n",
      "End_Time                   0\n",
      "Start_Lat                  0\n",
      "Start_Lng                  0\n",
      "                          ..\n",
      "Wind_Direction_Variable    0\n",
      "Wind_Direction_W           0\n",
      "Wind_Direction_WNW         0\n",
      "Wind_Direction_WSW         0\n",
      "Wind_Direction_West        0\n",
      "Length: 242, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Drop unnecessary columns\n",
    "columns_to_drop = ['ID',\n",
    "    'City', 'Amenity', 'Railway', 'Timezone', 'No_Exit', 'Traffic_Calming',\n",
    "    'Turning_Loop', 'Roundabout', 'Bump', 'Source', 'Street',\n",
    "    'Zipcode', 'County', 'Country', 'Airport_Code', 'Description'\n",
    "]\n",
    "df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Step 2: Handle missing values\n",
    "numerical_cols = ['Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)',\n",
    "                  'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)',\n",
    "                  'Precipitation(in)']\n",
    "for col in numerical_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "categorical_cols = ['Civil_Twilight', 'Weather_Timestamp', 'Weather_Condition',\n",
    "                    'Sunrise_Sunset', 'Nautical_Twilight', 'Astronomical_Twilight']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "# Impute missing values for End_Lat and End_Lng using Start_Lat and Start_Lng\n",
    "df['End_Lat'] = df['End_Lat'].fillna(df['Start_Lat'])\n",
    "df['End_Lng'] = df['End_Lng'].fillna(df['Start_Lng'])\n",
    "\n",
    "# Fill missing values for Wind_Direction with 'Unknown'\n",
    "df['Wind_Direction'] = df['Wind_Direction'].fillna('Unknown')\n",
    "\n",
    "# Step 3: Convert datetime columns to Unix timestamps\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'], errors='coerce')\n",
    "df['End_Time'] = pd.to_datetime(df['End_Time'], errors='coerce')\n",
    "\n",
    "df['Start_Time'] = df['Start_Time'].apply(lambda x: x.timestamp() if pd.notnull(x) else None)\n",
    "df['End_Time'] = df['End_Time'].apply(lambda x: x.timestamp() if pd.notnull(x) else None)\n",
    "\n",
    "# Step 4: Encode categorical columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorical_columns = [\n",
    "    'ID', 'Start_Time', 'End_Time', 'State', 'Weather_Timestamp',\n",
    "    'Wind_Direction', 'Weather_Condition', 'Sunrise_Sunset',\n",
    "    'Nautical_Twilight', 'Astronomical_Twilight', 'Crossing',\n",
    "    'Give_Way', 'Junction', 'Station', 'Stop', 'Traffic_Signal', 'Civil_Twilight'\n",
    "]\n",
    "columns_to_encode = ['State', 'Weather_Condition', 'Wind_Direction']\n",
    "label_encoded_columns = [col for col in categorical_columns if col not in columns_to_encode]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in label_encoded_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = label_encoder.fit_transform(df[col].astype(str))\n",
    "\n",
    "df = pd.get_dummies(df, columns=columns_to_encode, drop_first=True)\n",
    "\n",
    "# Step 5: Verify the updated DataFrame\n",
    "print(\"\\nUpdated DataFrame Schema:\")\n",
    "print(df.info())\n",
    "\n",
    "# Step 6: Check for remaining missing values\n",
    "print(\"\\nMissing Values After Handling:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names and Data Types:\n",
      "Severity                     int64\n",
      "Start_Time                   int32\n",
      "End_Time                     int32\n",
      "Start_Lat                  float64\n",
      "Start_Lng                  float64\n",
      "                            ...   \n",
      "Wind_Direction_Variable       bool\n",
      "Wind_Direction_W              bool\n",
      "Wind_Direction_WNW            bool\n",
      "Wind_Direction_WSW            bool\n",
      "Wind_Direction_West           bool\n",
      "Length: 242, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "print(\"Column Names and Data Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82613,
     "status": "ok",
     "timestamp": 1744787597126,
     "user": {
      "displayName": "Harshit Singh",
      "userId": "00023943354994433821"
     },
     "user_tz": 300
    },
    "id": "bEhmAQ-s0hfP",
    "outputId": "82b3beb2-ab29-4aea-d780-f181f370e0a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (7728394, 242)\n",
      "Missing Values:\n",
      " Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "\n",
    "\n",
    "# Compute the missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1744790194462,
     "user": {
      "displayName": "Harshit Singh",
      "userId": "00023943354994433821"
     },
     "user_tz": 300
    },
    "id": "oDMkL7AKkyHo",
    "outputId": "44660b9f-2475-47aa-ebcb-4cf6165e36ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyarrow in c:\\users\\manoj\\appdata\\roaming\\python\\python312\\site-packages (19.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns: ['Severity', 'Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)']\n",
      "Categorical Columns: ['State_AR', 'State_AZ', 'State_CA', 'State_CO', 'State_CT', 'State_DC', 'State_DE', 'State_FL', 'State_GA', 'State_IA', 'State_ID', 'State_IL', 'State_IN', 'State_KS', 'State_KY', 'State_LA', 'State_MA', 'State_MD', 'State_ME', 'State_MI', 'State_MN', 'State_MO', 'State_MS', 'State_MT', 'State_NC', 'State_ND', 'State_NE', 'State_NH', 'State_NJ', 'State_NM', 'State_NV', 'State_NY', 'State_OH', 'State_OK', 'State_OR', 'State_PA', 'State_RI', 'State_SC', 'State_SD', 'State_TN', 'State_TX', 'State_UT', 'State_VA', 'State_VT', 'State_WA', 'State_WI', 'State_WV', 'State_WY', 'Weather_Condition_Blowing Dust / Windy', 'Weather_Condition_Blowing Sand', 'Weather_Condition_Blowing Snow', 'Weather_Condition_Blowing Snow / Windy', 'Weather_Condition_Blowing Snow Nearby', 'Weather_Condition_Clear', 'Weather_Condition_Cloudy', 'Weather_Condition_Cloudy / Windy', 'Weather_Condition_Drifting Snow', 'Weather_Condition_Drifting Snow / Windy', 'Weather_Condition_Drizzle', 'Weather_Condition_Drizzle / Windy', 'Weather_Condition_Drizzle and Fog', 'Weather_Condition_Dust Whirls', 'Weather_Condition_Duststorm', 'Weather_Condition_Fair', 'Weather_Condition_Fair / Windy', 'Weather_Condition_Fog', 'Weather_Condition_Fog / Windy', 'Weather_Condition_Freezing Drizzle', 'Weather_Condition_Freezing Rain', 'Weather_Condition_Freezing Rain / Windy', 'Weather_Condition_Funnel Cloud', 'Weather_Condition_Hail', 'Weather_Condition_Haze', 'Weather_Condition_Haze / Windy', 'Weather_Condition_Heavy Blowing Snow', 'Weather_Condition_Heavy Drizzle', 'Weather_Condition_Heavy Freezing Drizzle', 'Weather_Condition_Heavy Freezing Rain', 'Weather_Condition_Heavy Freezing Rain / Windy', 'Weather_Condition_Heavy Ice Pellets', 'Weather_Condition_Heavy Rain', 'Weather_Condition_Heavy Rain / Windy', 'Weather_Condition_Heavy Rain Shower', 'Weather_Condition_Heavy Rain Shower / Windy', 'Weather_Condition_Heavy Rain Showers', 'Weather_Condition_Heavy Sleet', 'Weather_Condition_Heavy Sleet / Windy', 'Weather_Condition_Heavy Sleet and Thunder', 'Weather_Condition_Heavy Smoke', 'Weather_Condition_Heavy Snow', 'Weather_Condition_Heavy Snow / Windy', 'Weather_Condition_Heavy Snow with Thunder', 'Weather_Condition_Heavy T-Storm', 'Weather_Condition_Heavy T-Storm / Windy', 'Weather_Condition_Heavy Thunderstorms and Rain', 'Weather_Condition_Heavy Thunderstorms and Snow', 'Weather_Condition_Heavy Thunderstorms with Small Hail', 'Weather_Condition_Ice Pellets', 'Weather_Condition_Light Blowing Snow', 'Weather_Condition_Light Drizzle', 'Weather_Condition_Light Drizzle / Windy', 'Weather_Condition_Light Fog', 'Weather_Condition_Light Freezing Drizzle', 'Weather_Condition_Light Freezing Fog', 'Weather_Condition_Light Freezing Rain', 'Weather_Condition_Light Freezing Rain / Windy', 'Weather_Condition_Light Hail', 'Weather_Condition_Light Haze', 'Weather_Condition_Light Ice Pellets', 'Weather_Condition_Light Rain', 'Weather_Condition_Light Rain / Windy', 'Weather_Condition_Light Rain Shower', 'Weather_Condition_Light Rain Shower / Windy', 'Weather_Condition_Light Rain Showers', 'Weather_Condition_Light Rain with Thunder', 'Weather_Condition_Light Sleet', 'Weather_Condition_Light Sleet / Windy', 'Weather_Condition_Light Snow', 'Weather_Condition_Light Snow / Windy', 'Weather_Condition_Light Snow Grains', 'Weather_Condition_Light Snow Shower', 'Weather_Condition_Light Snow Shower / Windy', 'Weather_Condition_Light Snow Showers', 'Weather_Condition_Light Snow and Sleet', 'Weather_Condition_Light Snow and Sleet / Windy', 'Weather_Condition_Light Snow with Thunder', 'Weather_Condition_Light Thunderstorm', 'Weather_Condition_Light Thunderstorms and Rain', 'Weather_Condition_Light Thunderstorms and Snow', 'Weather_Condition_Low Drifting Snow', 'Weather_Condition_Mist', 'Weather_Condition_Mist / Windy', 'Weather_Condition_Mostly Cloudy', 'Weather_Condition_Mostly Cloudy / Windy', 'Weather_Condition_N/A Precipitation', 'Weather_Condition_Overcast', 'Weather_Condition_Partial Fog', 'Weather_Condition_Partial Fog / Windy', 'Weather_Condition_Partly Cloudy', 'Weather_Condition_Partly Cloudy / Windy', 'Weather_Condition_Patches of Fog', 'Weather_Condition_Patches of Fog / Windy', 'Weather_Condition_Rain', 'Weather_Condition_Rain / Windy', 'Weather_Condition_Rain Shower', 'Weather_Condition_Rain Shower / Windy', 'Weather_Condition_Rain Showers', 'Weather_Condition_Rain and Sleet', 'Weather_Condition_Sand', 'Weather_Condition_Sand / Dust Whirls Nearby', 'Weather_Condition_Sand / Dust Whirlwinds', 'Weather_Condition_Sand / Dust Whirlwinds / Windy', 'Weather_Condition_Sand / Windy', 'Weather_Condition_Scattered Clouds', 'Weather_Condition_Shallow Fog', 'Weather_Condition_Shallow Fog / Windy', 'Weather_Condition_Showers in the Vicinity', 'Weather_Condition_Sleet', 'Weather_Condition_Sleet / Windy', 'Weather_Condition_Sleet and Thunder', 'Weather_Condition_Small Hail', 'Weather_Condition_Smoke', 'Weather_Condition_Smoke / Windy', 'Weather_Condition_Snow', 'Weather_Condition_Snow / Windy', 'Weather_Condition_Snow Grains', 'Weather_Condition_Snow Showers', 'Weather_Condition_Snow and Sleet', 'Weather_Condition_Snow and Sleet / Windy', 'Weather_Condition_Snow and Thunder', 'Weather_Condition_Snow and Thunder / Windy', 'Weather_Condition_Squalls', 'Weather_Condition_Squalls / Windy', 'Weather_Condition_T-Storm', 'Weather_Condition_T-Storm / Windy', 'Weather_Condition_Thunder', 'Weather_Condition_Thunder / Windy', 'Weather_Condition_Thunder / Wintry Mix', 'Weather_Condition_Thunder / Wintry Mix / Windy', 'Weather_Condition_Thunder and Hail', 'Weather_Condition_Thunder and Hail / Windy', 'Weather_Condition_Thunder in the Vicinity', 'Weather_Condition_Thunderstorm', 'Weather_Condition_Thunderstorms and Rain', 'Weather_Condition_Thunderstorms and Snow', 'Weather_Condition_Tornado', 'Weather_Condition_Unknown', 'Weather_Condition_Volcanic Ash', 'Weather_Condition_Widespread Dust', 'Weather_Condition_Widespread Dust / Windy', 'Weather_Condition_Wintry Mix', 'Weather_Condition_Wintry Mix / Windy', 'Wind_Direction_Calm', 'Wind_Direction_E', 'Wind_Direction_ENE', 'Wind_Direction_ESE', 'Wind_Direction_East', 'Wind_Direction_N', 'Wind_Direction_NE', 'Wind_Direction_NNE', 'Wind_Direction_NNW', 'Wind_Direction_NW', 'Wind_Direction_North', 'Wind_Direction_S', 'Wind_Direction_SE', 'Wind_Direction_SSE', 'Wind_Direction_SSW', 'Wind_Direction_SW', 'Wind_Direction_South', 'Wind_Direction_Unknown', 'Wind_Direction_VAR', 'Wind_Direction_Variable', 'Wind_Direction_W', 'Wind_Direction_WNW', 'Wind_Direction_WSW', 'Wind_Direction_West']\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical columns\n",
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print(\"Numerical Columns:\", numerical_columns)\n",
    "\n",
    "# Identify categorical columns based on data types\n",
    "string_columns = df.select_dtypes(include=['object']).columns.tolist()  # Changed from 'string[pyarrow]' to 'object'\n",
    "bool_columns = df.select_dtypes(include=['bool']).columns.tolist()\n",
    "\n",
    "# Combine both lists\n",
    "categorical_columns = string_columns + bool_columns\n",
    "\n",
    "# Print the identified categorical columns\n",
    "print(\"Categorical Columns:\", categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity\n",
      "2    6156981\n",
      "3    1299337\n",
      "4     204710\n",
      "1      67366\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Severity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of columns after encoding:\n",
      "Severity                     int64\n",
      "Start_Time                   int32\n",
      "End_Time                     int32\n",
      "Start_Lat                  float64\n",
      "Start_Lng                  float64\n",
      "                            ...   \n",
      "Wind_Direction_Variable       bool\n",
      "Wind_Direction_W              bool\n",
      "Wind_Direction_WNW            bool\n",
      "Wind_Direction_WSW            bool\n",
      "Wind_Direction_West           bool\n",
      "Length: 242, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of the columns\n",
    "print(\"Data types of columns after encoding:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "Severity\n",
      "2    6156981\n",
      "3    1299337\n",
      "4     204710\n",
      "1      67366\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manoj\\AppData\\Local\\Temp\\ipykernel_15740\\3793978917.py:26: UserWarning: The palette list has more values (8) than needed (4), which may not be intended.\n",
      "  barplot = sns.barplot(data=class_df, x='Severity', y='Count', hue='Severity', palette=palette, legend=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAJICAYAAADxUwLTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABryklEQVR4nO3dd3yN5//H8fcJmcQIqvZOjAgxalSIKC0aVKtW7VGjVat0aEtpq/b48kUpapTamxpFUbX33qSIPYOM8/vDL/c3pwnunIRz8Ho+HnnIue/7XPfnnJzI/b6v67pvi9VqtQoAAAAATHBxdAEAAAAAnh8ECAAAAACmESAAAAAAmEaAAAAAAGAaAQIAAACAaQQIAAAAAKYRIAAAAACYRoAAAAAAYBoBAgAeIyoqytElJNmL8BqQvPhMAEgKAgTgRG7duqVx48apQYMGKlu2rPz9/VW+fHm1atVKc+fOVWRkZLznzJ07V35+fvLz81OTJk0cUHXyaNKkifE64n4VKVJEpUqVUp06dTRgwACdP38+wed/9tlnxnNGjhyZ5HrCw8PVs2dPLV68ONHPjfta5s6d+9RqNGPjxo2qXbt2vOUhISFGLX///fczqeVZmDVrlurUqaNixYopMDBQoaGh+uOPPxLcduTIkQl+5h73de7cuWf8ipLf0qVL1axZM1PbxX3tZ86ceeS2f/75p7FdwYIFFRYWlpwlS5L+/vtvYx8hISFJasuez/+5c+ds3g/gZZbS0QUAeGjDhg3q1q2brl+/brP8ypUr2rBhgzZs2KCpU6fqv//9rzJnzuyYIh0gKipKt27d0sGDB3Xw4EH99ttvGjp0qIKCgp7aPn/99VcNGDBAd+/eVZkyZZ7afp6mu3fvqnv37lq9erWjS3lmVq1apV69etksO3LkCGfb/194eLi6dOmibdu2KVu2bE/cPiQkRKlSpdKdO3ckPQwU7dq1S3DbFStWGN+XLFnSVPsAnl8ECMAJbN68WR9++KFxoJMpUyYFBQXJ09NTu3fv1r59+yRJ+/fvV8eOHTV9+nS5ubk5suSnqkSJEipZsqRiYmL04MED/fPPP9qwYYPu37+vW7duqVOnTpo9e7by5ctnPKdSpUrKmDGjpIcHMEmxdOlS3b171+7nv/322ypWrJgkydfXN0m12Ovq1auPDQ8NGjTQzZs3JUlZs2Z9VmU9VZs3bza+z5gxo2rWrKl79+4pICAgwe1LliypNm3a2CxbvHix0csV+zmMy9vbO5mrfnZOnjypbdu2md7ew8NDVatW1fz58yU9OkBER0fbfNZCQ0OTXGtCsmbNavy80qRJ81T2AcAcAgTgYPfv39enn35qhIfq1avrhx9+kKenp7HNtGnT9O2330qS9u7dq2XLliU4LOVFUb58eX388cc2y86ePaumTZvqn3/+0d27dzVw4ECNGTPGWF+9enVVr179WZeaoPr16zu6hCdq27ato0tIdrFnyiXpvffeU5cuXR67ffny5VW+fHmbZbt37zYCREKfw5dNaGioESAOHz6s48eP2wR3SdqyZYuuXr0qSXJ1ddVbb731VGrJkSOHunfv/lTaBpA4zIEAHGzhwoUKDw+XJGXJkkX9+/e3CQ+S1LhxY1WuXFleXl4qV66cXFzM/eo+ePBAY8eOVZ06dRQYGKhChQqpdOnSatCggXFQENe9e/c0ZswY1a1bV4GBgSpcuLDKlCmjJk2aJLi9JO3atUudOnVSUFCQ/P39FRAQoGrVqumbb7555HwFe+TIkUNffPGF8Xjt2rU27T9ufoHZGmPHOG/ZssVY9vnnn9vMZYi7nzVr1qhfv34qUaKEAgMDjYObR82B+Lfdu3eradOmKl68uMqUKaNOnTrp+PHj8bZ73Bj8hF73yJEjVaVKlQTbiPWkMeC7du1S9+7dFRISIn9/f5UrV07t27fXhg0b4m0bd2z4+++/r6ioKP3000966623VLRoUYWEhGjw4MGKiIh45HuRkLCwMP3444+qXr26ihcvrlKlSqlRo0aaMWOGzbCk2LHxcd/rMWPGPLV5QeHh4erTp4+qVq2qokWLqnDhwnr99dfVrl077dy502bbuOP2u3TpotWrV6tq1ary9/dX1apVdfbsWUmS1WrVr7/+qtq1aysgIEBBQUH67rvvdPv2bTVv3vyRP/+LFy+qT58+qly5svz9/fX666/r448/1u7du222++yzz9S0aVPjcVhYmKm5BOXKlVOmTJmMx8uWLYu3zfLly43vg4KClC5dOkkP53QNHjxYNWrUULFixYz/T5o3b65169bZtPHvz9DOnTsVGhoqf39/BQcHa+fOnY+dA2G1WjVt2jTVr19fJUuWVKFChVSiRAnVrVtXv/zyi6Kjox/7OufPn6/Q0FAVLVpUwcHB+u6773Tjxo3HPuffzP4sgBcBPRCAg61du9b4vmbNmvLw8EhwuwEDBsjLy0spU5r7tY2JiVHXrl21cuVKm+U3b97Uzp07tXPnTp05c0adOnWS9HCuQcuWLbV9+3ab7a9fv64tW7Zoy5YtNttL0h9//KGOHTvG++N8+vRpnT59WuvWrdP06dOTbYhMcHCw3Nzc9ODBA1mtVm3btu2JwyWeZo3Dhg3T4cOHjcc5cuQw/dy///5bY8eONSbGR0REaMWKFfrzzz/1888/KzAwMNH1JJcxY8Zo+PDhiomJMZZdvXpVa9as0Zo1a/TBBx/oq6++SvC5UVFR6tixo83nOiwsTOPGjdPRo0dteo0eZ/369eratatu3bpls3z79u3avn27Fi5cqDFjxjzzoSxXr17VBx98oNOnT9ssv3z5sv744w+tX79e48ePj9ezIUmHDh3SypUrjZ95VFSUsmfPLulhUJ03b56xbXh4uH755Rdt27ZNrq6uCdZy6NAhtWzZUleuXLGp4/fff9eqVav07bffql69ekl6vSlSpFD16tX1yy+/SHo4jOmjjz4y1sfExGjVqlXG49jfx3v37ql169batWuXTXvXr1/XX3/9pb/++kvff/+93n333Xj7vHTpktq2bWsMsbt27Zp8fX2NoZwJ+e677zRlyhSbZXfu3NH+/fuNrx9//DHB544ZM0abNm0yHp8/f16//PKL/vzzT/36669Knz79I/cb61n8LABnQg8E4GAHDhwwvi9SpMgjt0uTJo3p8CA9PHCODQ+pU6dWvXr11KRJExUqVMjYZvLkybJarZKk33//3QgP6dOnV926ddW8eXOVK1fO2H706NE2B04DBw40Dsxfe+01NW3aVO+//77xB/f8+fMaNmyY6ZqfxNXVVbly5TIeHzt27InPSUyN3t7eatOmjbJkyWI8v1KlSmrTpk2CcxkOHz6snDlz6oMPPlDhwoX19ttvm34tW7dulaurq2rXrq3atWsbvU6xk5+TMvG3ZMmSatCggc2yNm3axBvvn5Dff/9dQ4cONcJDkSJF1KhRI5UuXdrYZurUqRo/fnyCz9+/f7/Wrl2rkiVLqkmTJsYBsvTwM3ny5Mkn1nDu3Dl16dLFCA9ZsmTR+++/rzfffNM4mN6+fbvR4xM7Nj7uz6hEiRJq06ZNon4mZowdO9b4HciRI4eaNGmi+vXrG2fpo6OjjYPtfztx4oQsFovq1q2rt956S7Vq1ZLFYtHixYttwkPhwoXVqFEjFS1aVAcOHEjwDHZkZKQ++eQT44A1e/bsatiwoSpVqiTp4YF9nz59dOTIEUkPP8dx34vUqVOrTZs28T4nCYkb0o8fP24Tmrdt26bLly9LklKlSmX0DPz2229GeMiYMaMaNWqkxo0b2/z+Tpo0KcH9/fPPP7p9+7Zq1KihOnXqqEaNGkqVKtUj6zt8+LARHtzc3FS7dm01a9ZMpUqVMrZZsGCBMczq3zZt2qQsWbKofv36Cg4ONpafPHlSP/zwwyP3GyuxPwvgRUAPBOBg165dM75PmzZtsrXr4eGhevXq6fDhw/rkk09UoUIFSQ/PDJYrV053797V7du3de3aNfn4+BhDKSSpa9euev/9943HQ4cOVVhYmPLnz29zVjr2so5ZsmTR5MmTjaFVrVu31rfffqt8+fKpcOHCyfaapIcHPrFiz1A+TmJqTJs2rbp3724zDv6tt95S3bp1E2zb3d1d06dPtxniYVbKlCk1ffp0I9C1aNFC77//vh48eKBz585p48aNxgFIYpUvX145c+bUjBkzjGVmx44PHjzY+L5+/frq3bu38Z6NHTtWQ4YMkfQwTNavXz/BScUNGjRQnz59JEnNmjVTzZo1df/+fUkPQ1+ePHkeW8PYsWN1+/ZtSVLRokU1ceJEYz/btm1T06ZNFR0drXXr1umvv/5SuXLl1L17d12+fNk4SHta8xdy586tt99+WydPntT48ePl4+MjSapVq5YaN24sSTa/S//WvXv3eJdQnT59uvH9G2+8oREjRihFihSyWq364osvEhwGt3LlSp06dUqSlDdvXs2dO9cIoePHj9fAgQMVGRmpyZMn67vvvlP16tXl4+NjXJY49rNuRkBAgHLnzm3sL/byrpLt1ZeqVatm9KBmzJhRderU0ZEjRzRw4EDlz59f0sPAHnuQ/rj3qUmTJjZDFh/n/v37atSokQ4dOqR3331X7733nqSHw5refPNNnT59WlarVefOnTN+XnHlypVLs2fPNnqzpk+fbnx+ly5dqq+++uqxk+cT+7MAXgQECMDB4p5pjntwnlSvv/66Xn/9dePx/fv3tW/fPv31119Gr4P0MFBIsjnQ79u3r9atW6dy5cqpRIkS+uSTTxKcd1GkSBHt2rVL58+fV/Xq1RUSEqKSJUuqZMmSmjBhQrK9lrji1v6kcc1Pu8ayZcvaFR6kh8Ox4vYGFSpUSEFBQcbVbHbt2mV3gLDXwYMHjQMhT09P9ejRw+bn3rp1a82cOVNhYWG6c+eO/vrrL1WrVi1eOy1atDC+z5Ejh/LmzauDBw9Ksp3o/Chxx9l369bN5uCtVKlSqlmzphYuXChJWr16tU0v2dPWsGFDNWzY0Hh8/fp17d6922aoYOzvVEL+PeQuMjJSe/bsMR63a9dOKVKkkCRZLBZ17tw5wQAR94pToaGhNvOm6tatq4EDB0qS/vrrL7Mv7bFCQ0ONOTZLly5Vly5dZLVa9fvvv9tsE6tGjRqqUaOG8fj27dvau3evNm7caCx73PuUmJ6jgIAAmyttRUZG6vDhw9q8ebPNELjYEPtvjRs3thkKV79+fQ0fPlzXr19XZGSk9u3b99jP2LP+WQDO4KULEKNHj9Zff/0Vb6zkk8yfP1/jxo3T2bNnlTNnTn300UdOc8UXPN/SpUunS5cuSVK8e0AkVVhYmGbMmKGNGzfq8OHDCQ6LiQ0tQUFBatiwoX799Vc9ePBAq1atMsY2p02bVlWqVFHLli1VoEAB47l9+vRR69atdenSJZ06dUo///yzfv75Z1ksFvn7+6tu3bqqV6/eI8dw2yPuAaiZS2o+zRqTcq37uEM5YuXNm9cIEHHHUj9OcobOuMPTcubMadPbIz0cD+/n52fcJOxRNxaLOwRMks3wkyfVe/XqVZuDvoR6sIoUKWIEiMfd3Oxp2bVrl2bPnq0tW7bEmwsh2YbcuDw9PeOdAY89SI31796ZzJkzy9vbO95ckLiT/4cPH67hw4cnuM+wsDBFRETEuzBDYsUNEGfOnNG+fft0//594wIQmTJlUtmyZW2ec+zYMc2YMUObN2/W8ePH4/3sH/U+SbIZ+mbG1atXNXPmTK1bt0779+/XgwcP4m3zqM9e7ty5bR6nSJFCuXLlMv4/ftLv4rP+WQDO4KUKEJMmTdKIESNsxvKasWDBAn3xxRfq2bOngoODtXjxYnXt2lWvvvqqQyc64sXg5+dnBIgDBw48clLw9OnTtWPHDlWrVs24R8TjbN++Xa1bt9bdu3fl4uJinHUPDAzUV199Zfzhj6t3796qW7euFi5cqD///NM4G33jxg3NnTtXixYt0qRJk4yxxQULFtTy5cu1ePFirVq1Stu2bVNERISsVqv27t2rvXv3au3atRo7dqwsFksS3qWHoqOjbQ4YnzQU5mnX+O8D7MRI6K7icXtUYs9C/9u/D7oSasdeZubYxN3/o94vd3d3m8dmrxomyVSQM1PD0zJp0iT1799fVqtVXl5eCgkJUWBgoLJnz/7Ey8Ym9Hl53EF0rIReY9yD4dSpUz/y4gvSw3k1ST1ozZUrlwICAozekqVLl9qckKhRo4bNZ3b58uXq3r27IiMj5erqqvLlyyswMFAlS5ZU8+bNn7i/xPxunTp1So0aNTIO9P39/fXaa6+pePHi+umnn7R3797HPj+h36G4r+1Rv4uxnvXPAnAGL0WAuHjxor788ktt377d1AFHXFarVcOHD1ezZs2McasdO3bUjh07tGXLFgIEkiw4ONi4NOby5cvVpUuXeDeJi46O1q+//qojR45o0aJFql27tgYMGPDYdvv372/cDG3QoEGqWbOmse5xE3Rz5cqlHj16qFevXgoPD9f27ds1depUbdu2TZGRkfrvf/9rM/TH09NT1apVU4MGDRQZGamDBw9q48aNGjVqlCIjI7Vu3Trt2rUrWX5Xtm7dagxDsFgspu8S/bRqTErPytGjR+Mtiw1skvTKK68Y37u4uBgHKf++FGrcOTRJFbdH5cyZM7p9+7bNgVx0dLTNRNCEelGSytvb2+aM+4EDB+INH4l74YGnUcOj3LhxQ0OGDJHVapWrq6sWL15svGdmJvQn9HlJnz69XF1djYPYEydO2AzHuXDhQoJzfeJ+Pj788EOb+3rExMQkKrSZFRoaagSI5cuX2xw4xz3xERMTo379+hmvaerUqSpevLik+J/fR0nM79awYcOM8NCtWzeb9+Knn3564vOPHDmiN954w3gcHR1t9LJJtu91QhzxswAc7aX4VO/fv19p06bVwoULjbvDxvXHH3+obt26CggIUNWqVTVs2DCj+/PEiRMKCwuLd1Z4woQJ+vDDD59J/Xix1a1b1xjW8M8//+jLL7+06X6PiYnRoEGDbA7cYicJPs6hQ4eM7+NOzt6wYYPN1Uhiz4B+9dVXqlChgl577TVNnjxZ0sM/jNWrV7cZ8x3bXb9nzx6FhoaqWLFiqlOnjm7cuCFXV1cFBASoXbt2NkMQkuN+ELdu3dKgQYOMx8HBwU+8bKq9Ncb9g/+4sJWUs9+bN2+2uSvwoUOHtH79euNx3Dsgxx2fHfdSlhcuXHjkNeb/fdbUTE9FwYIFjQPiiIgIDR482OYM+c8//2wcWHl7e8cbspJc4l7jf+jQocaEaulhz9qSJUuMxwnNwXhaTp48aQTYFClS2Ayhix1SJT16qExCnxdXV1ebv0tjx441eqJif/cT8tprrxnfz5kzx+Y9mjp1qkqUKKH3339f//nPf4zlcT8T9vRc1axZ02gjLCzM+J3JnTu3ihYtamx35coVo1dVsv3/J+77JCXuvXqUR/1fd+TIEZt1j9rXjBkzbIYpzZgxwxi+5Onp+cQLQdjzswCedy9FD0RISMgjb5azfv16ffLJJ/r888/1+uuv68yZM+rbt69Onjyp4cOHG2cE7969q1atWunAgQPKnj272rdv/8Qb8ABmpEqVSgMGDFDbtm0VExOjhQsXasuWLapYsaJcXFy0bds2m7ObNWrUsPmD9SiZMmUyDva6du2qGjVq6MqVK1qzZo3NdrETGf38/PTbb79JkoYMGaKtW7cqT548unLlijEuX5LN8KVr164pMjJSFy9eVK1atVSpUiW5ublp586dxuU6U6ZMaZx9NGvTpk3GgVpUVJQuX76sDRs2GGfbvby89Omnnz6xHXtrjHvWfcKECdq3b58qVqxoc5YyqaxWq1q0aKG33npLrq6uWr58uRFWfH19bYZaFipUyJiA+eOPP+rGjRuKiYnRlClTjF6mf/v3EJDOnTvLxcVFgwcPjtfDFctisah9+/bq1auXpIfD5nbv3q3ixYvr6NGjNjfY+/jjj5M0hOtxWrVqpeXLl+v+/fvavXu3QkNDFRQUpOvXr2vNmjXGAfYbb7xhc6nOpy3uhPl79+6pfv36ev3113XgwAGb+6c8bnJwQho3bmyEyVWrVqlevXoqVqyYdu3aZdPbEtdbb72loUOH6uLFizp16pSqV6+uypUr686dO1qxYoUiIyO1e/dumyuIxf15hYeHq2fPnpL0yPsj/FuGDBlUrly5eDcT/PcJtjRp0sjd3d34HW7evLmqVq2qU6dOxXvuvXv35OXlZWr/j5IpUybjd/n777/Xnj17dP/+fZt7bkiPnkQd+39DtWrVdOnSJZv7Wrz77rtPHHJkz88CeN69FAHiccaMGaP33nvPOMOaM2dO9enTR82aNdO5c+eMMwk9e/bURx99pO7du2vFihXq0KGDJk6c+Eyv/oEXV1BQkEaNGqVPP/1Ut2/f1oULF4yD+bgqV65s+jKArVq10rfffivp4dCLX3/91VgXd4jIuXPnVKBAATVq1Eh79uzRggULFBMTo3Xr1sW7W2zu3LnVuXNnSQ+vt/7f//5XLVq00K1bt3ThwgXNnDkzXh09evRI9E3aduzYoR07diS4Lk2aNBoyZIjy5cv3xHbsrbFkyZLGQcSpU6d06tQpZcyYMVkDROPGjTVz5sx4Z2TTpk2rgQMH2pyBbdWqlTZv3iyr1arr16+rf//+kh4GqXfeecfmHgKxvL295evra/Rcxb6eixcvPrbnpl69ejp9+rTGjx8vq9Vq3IQrrpYtW8a7FGly8vPz04ABA/T555/r7t27+ueff+L93MqUKWP6wDe5ZMuWTW+99ZZx5+UTJ07oxIkTkh72JKRMmVIRERG6fv16vOFfj1OjRg2tXbtWCxYskCSb97xy5crasWOHcVfk2N4xT09PjRgxQi1bttSdO3cUHh4e7z0KDQ21uRxz3rx5lS5dOuPs+vz58+Xi4qLvvvvO9D1mQkNDnxgg3N3d9cEHHxhDHS9cuGBcuMRisSh16tTG39Zz584leI+VxGjVqpW2bt0qq9Wqe/fuafbs2ca6f/9fl5BmzZpp8uTJNpfTlR4G9yfNa5Hs+1kAz7uXYgjT4xw4cEC//fabAgMDja927dpJenjDnNhxmK1atdI777yjQoUKqXPnzqpYsaImTpzoyNLxggkJCdHKlSvVsWNHFSlSRKlTp5arq6syZcqkKlWqaNSoURozZozps3WNGzfWsGHDVLRoUaVKlUoZMmRQyZIlNXDgQOPMoySjd8HFxUU//vijRo0apaCgIGXLlk2urq7y8vJSkSJF9PHHH2vOnDk2V5EpWrSolixZojZt2sjPz09p06aVq6urMmfOrDfffFNTpkxJ8oFmihQplCZNGvn7+6tDhw5asmSJgoKCTD/fnho/+OADNWnSRD4+PnJzc1POnDmT7W7asYKDgzV9+nRVqFBBXl5eSpcunWrUqKHZs2erYMGCNtsGBQVp7NixCgwMNK7kU7NmTc2dOzfBYZmxBg0apDJlysjd3V2pU6c2Pceje/fumjZtmmrVqqWsWbPK1dVVPj4+CgkJ0aRJk2w+P0/LW2+9pYULF6pFixbKmzevPDw8lCpVKpUsWVL9+vXTxIkTn1oPyOMMHDhQXbp0Ud68eeXu7q6sWbOqcuXKmjZtmqpWrSrpYe/Sv3v6nqR///764osvlC9fPrm5uSlbtmz6+OOPjSsfxYp7Nrx48eJasmSJGjdurJw5c8rd3V3p06dXiRIl9OOPP2rAgAE2w/Hc3Nw0cuRIFS1aVK6urkqbNq3KlCmTqB6TqlWr2tQQEBCQ4DyU7t27q3fv3vLz85Onp6deeeUVlS9fXuPGjVOTJk2M7eL2btorODhYEydOVOnSpZUmTRqlS5dORYsW1ZdffmlzI8tH7atbt24aMGCAChcuLDc3N2XJkkUtW7bU1KlTTX/GEvuzAJ53FquZS0C8QD777DOFhYUZZ0MCAgLUsmVLvfPOO/G2zZQpkw4dOqSGDRtq2rRpNl3lAwYM0Nq1a7V06dJnVjsA4MUzf/583bhxQ+nSpVOWLFlshiiePXtW1apVU0xMjFKlSqXt27c/8ytPAcC/vfRDmAoUKKATJ07YnEHZsmWLJk+erN69e6tw4cJKlSqVdu/ebRMgjhw5opw5czqiZADAC+Tvv/+2uVlc9erVlSVLFl2/fl3r1q0zJv8GBwcTHgA4hZc+QLRp00adO3fWyJEj9fbbb+vChQvq1auXsmbNakyYa926tUaNGqXMmTMrICBAS5Ys0caNGzVp0iTHFg8AeO61bt1aq1atMi7XGvdO3LF8fHyM+UcA4Ggv/RAm6eF/1mPHjtWxY8eUNm1aVa5cWZ9++qnN5eAmTpyoqVOn6uLFi8qXL58+/vjjZJ1QCQB4eZ07d04TJ07Uli1bdO7cOd27d08eHh7Knj27KlSooBYtWjzxfgQA8Ky8dAECAAAAgP24JAAAAAAA0wgQAAAAAEx7YSdR79y5U1ar1biPAwAAAICERUZGymKxmLpn0AsbIKxWq5jeAQAAADxZYo6bX9gAEdvzULRoUQdXAgAAADi3vXv3mt6WORAAAAAATCNAAAAAADCNAAEAAADANAIEAAAAANMIEACcypIlSxQaGqqiRYvqzTff1IIFC574nK1bt8rPz0/vv/9+vHVvvvmm/Pz8bL7q1q1rrI+KitKIESMUHBys4sWLq0GDBtqzZ89j97do0SKFhoaqWLFiqlmzppYuXWqz/tKlS/r0009VoUIFBQYGqkGDBtq8eXOCbf3nP/+Rn5+fBg0a9MTXCQCAMyBAAHAa8+fPV9euXXX69GkFBgYqLCxMPXv2fOTBtyQdP35cXbt2TXDdnTt3dObMGaVOnVpVqlQxvsqUKWNs89VXX2nUqFF68OCBChYsqJ07d6pNmza6evVqgm0uXLhQ3bt3V3h4uAICAnTixAl16dJFv//+u7FN586dtXDhQrm5ualQoULauXOnPvzwQ506dcqmreXLl2vMmDGJeIcAAHC8F/YyrgCeLzExMRo8eLAkadiwYQoJCdHPP/+s8ePHa9u2bSpbtqzN9tHR0frvf/+r8ePHKyIiIsE2Dx48qJiYGJUsWVKjR4+Ot/748eOaO3euvLy8NG/ePGXOnFkdO3bUgQMHtHfvXlWqVCnec8aPHy9JmjBhgvz9/TVp0iT98MMPGjlypKpVq6abN29q27Zt8vLy0sKFC5U6dWr16NFDCxYs0Pr165U7d25dunRJgwcP1rx585L6tgEA8MwRIAA4hSNHjig8PFzu7u4KDg6WJLVs2VItW7ZMcPs7d+5o5MiRypYtm4KDgzVt2rR42xw8eFCSdPfuXX322WdycXFRaGioypUrJ0nasGGDJCkwMFCZM2eWJI0aNeqxdZ45c0aS5OvrK0kKCgrSDz/8oCNHjujq1atKlSqVvLy8bJ4Te3Meb29vSdLu3bs1b948lS1bVm5ublq/fv3j3xwAAJwIQ5gAOIXYA/O0adNqwIABCgwMfOwcCFdXV3311VdavHix/P39E9zmwIEDkh7OkZg3b57mzJmj5s2ba/78+ZKks2fPSpJSpEihNm3aqHjx4qpfv7727dv3yDpfffVVSTLmScSGFEn6559/5O7urt69e0uSateurUaNGmnhwoUqW7asatSoIUnKli2bRo0apYkTJypDhgxm3h4AAJwGAQKAU7h7964kKTw8XLNmzVJAQIDCwsLUo0cPrVu3Lt72np6e+uCDD+Kd7Y8rW7ZsKlGihAYOHKjt27ere/fukqQffvhB9+/fN/a5fv16HTt2TAULFtSuXbvUvHlzhYeHJ9hmo0aNJElt27ZV8+bN9fnnnxvr7t27J0myWCyyWCw6d+6ctm/fLknKmTOnLBaLJKlQoUJ644035OLCf8EAgOcPf70AOAUPDw/j+wkTJmjy5Mnq27evJGnKlCl2tfnRRx/p119/Va1atZQ6dWq1bt1aqVKl0vXr13X8+HFjn+nTp9eiRYs0Y8YM1a1bV7du3TJ6Kf7tgw8+ULdu3ZQmTRodO3ZM3bp1M9Z5eXnp/Pnz+vzzz/XgwQNNmTJFW7ZsUUhIiH777TcNGTLErtcBAIAzIUAAcApZs2Y1vi9YsKAkKSAgQJJ04cKFRLdntVp19uxZ7dixQ9HR0ZIe9gy4urpKenj51th95siRQ6lTpza1TxcXF7Vt21Zr167Vhg0bVL16dWNdjhw5tHPnTkVFRalgwYJ67bXXlDZtWr333nuS/jfnAgCA5xkBAoBTKFSokNKlSydJ2rRpkyTp2LFjkh4O/7FHw4YN1bBhQ61evVqStGvXLl2/fl3e3t7Knz+/cWWnY8eOGUOWnrTPr7/+WuXLl9eqVaskyfi3WLFi8vb2Nl7D2bNndfPmTUn/mycRO1EbAIDnGVdhAuAUXF1d1a5dO/Xv31+dO3dWYGCg9uzZI4vFopYtW2rJkiVasmSJSpUq9cgrM8UV+7wff/xRXbt2VcmSJbV3715JUseOHeXl5SV/f39VrlxZf/zxh+rUqaO8efNq69atypAhg+rUqSNJGjp0qI4ePaqGDRsqKChIhQsX1syZM/XZZ5+pcOHC2r59u1KkSKHOnTtLkkqXLi0/Pz8dPnxYb7/9tnLlyqWtW7dK+t/8CQAAnmf0QABwGi1atFCvXr2UKVMm7dq1S3nz5tXYsWNVqlQpnThxQqtXr9b+/ftNt9eyZUt9/fXXxtCiDBkyqFevXmrRooWxzdChQ/XBBx8oOjpahw8fVsWKFTV16lSjJ2HHjh1avXq1/vnnH0lS/fr19fHHH8vLy0s7d+5U4cKFNW7cOJUvX17SwyA0adIkNWrUSBaLRXv37lXhwoU1YsQIValSJfneLAAAHMRijb1A+Qsm9kxj0aJFHVwJgOTy3XffKSYmRl999dUz3W+dOnXUvn17vfnmm890vwAAPCuJOXamBwLAc2HhwoVasmSJ6tWr90z326dPH0VHRysoKOiZ7hcAAGdFDwSA58K5c+eUOnVqY2jRs3L48GHly5dPKVMyZQwA8OJKzLEzfxEBPBeyZ8/ukP36+fk5ZL8AADgrhjABAAAAMI0AAQAAAMA0AgQAAAAA0wgQwEvGGhPj6BLwHOPzAwBgEjXwkrG4uOjGql8VfS3c0aXgOZMi/StK+0ZDR5cBAHAwAgTwEoq+Fq6oy2GOLgMAADyHGMIEAAAAwDQCBAAAAADTCBAAAAAATHO6ADF//nzVqFFDRYsWVc2aNbVs2TJHlwQAAADg/zlVgFiwYIG++OIL1a9fX4sXL1aNGjXUtWtX7dy509GlAQAAAJATBQir1arhw4erWbNmatasmXLlyqWOHTuqfPny2rJli6PLAwAAACAnuozriRMnFBYWptDQUJvlEyZMcFBFAAAAAP7NaXogTp06JUm6e/euWrVqpXLlyqlevXpas2aNYwsDAAAAYHCaHojbt29Lknr27KmPPvpI3bt314oVK9ShQwdNnDhR5cqVS3SbVqtVd+/eTe5SgeeWxWKRp6eno8vAcy4iIkJWq9XRZQAAkpHVapXFYjG1rdMECFdXV0lSq1at9M4770iSChUqpAMHDtgdICIjI3Xw4MFkrRN4nnl6eqpw4cKOLgPPuZMnTyoiIsLRZQAAkpmbm5up7ZwmQLz66quSJF9fX5vl+fPn19q1a+1q09XVVfnz509qacALw+yZBeBx8uTJQw8EALxgjh07ZnpbpwkQhQsXVqpUqbR7926VKlXKWH7kyBHlzJnTrjYtFou8vLySq0QAgMQwOAB4ASXmJKPTBAgPDw+1bt1ao0aNUubMmRUQEKAlS5Zo48aNmjRpkqPLAwAAACAnChCS1KFDB3l6emro0KG6ePGi8uXLp5EjR6pMmTKOLg0AAACAnCxASFKLFi3UokULR5cBAAAAIAFOcx8IAAAAAM6PAAEAAADANAIEAAAAANMIEAAAAABMI0AAAAAAMI0AAQAAAMA0AgQAAAAA0wgQAAAAAEwjQAAAAAAwjQABAAAAwDQCBAAAAADTCBAAAAAATCNAAAAAADCNAAEAAADANAIEAAAAANMIEAAAAABMI0AAAAAAMI0AAQAAAMA0AgQAAAAA0wgQAAAAAEwjQAAAAAAwjQABAAAAwDQCBAAAAADTCBAAAAAATCNAAAAAADCNAAEAAADANAIEAAAAANMIEAAAAABMI0AAAAAAMI0AAQAAAMA0AgQAAAAA0wgQAAAAAEwjQAAAAAAwjQABAAAAwDQCBAAAAADTCBAAAAAATCNAAAAAADCNAAEAAADANAIEAAAAANMIEAAAAABMI0AAAAAAMI0AAQAAAMA0AgQAAAAA0wgQAAAAAEwjQAAAAAAwjQABAAAAwDQCBAAAAADTCBAAAAAATCNAAAAAADCNAAEAAADANAIEAAAAANMIEAAAAABMI0AAAAAAMI0AAQAAAMA0AgQAAAAA0wgQAAAAAEwjQAAAAAAwjQABAAAAwDQCBAAAAADTCBAAAAAATCNAAAAAADCNAAEAAADANAIEAAAAANMIEAAAAABMS+noAuIKCwtTSEhIvOX9+vVTvXr1HFARAAAAgLicKkAcPnxY7u7uWrVqlSwWi7Hc29vbgVUBAAAAiOVUAeLIkSPKkyePXnnlFUeXAgAAACABTjUH4vDhw8qfP7+jywAAAADwCE7XA5EpUyY1atRIp06dUq5cudShQwcFBQXZ1Z7VatXdu3eTuUrg+WWxWOTp6enoMvCci4iIkNVqdXQZAIBkZLVabaYQPI7TBIgHDx7o1KlT8vT0VI8ePeTl5aWFCxeqTZs2mjhxosqVK5foNiMjI3Xw4MGnUC3wfPL09FThwoUdXQaecydPnlRERISjywAAJDM3NzdT2zlNgHBzc9PWrVuVMmVKo3h/f38dP35cEyZMsCtAuLq6MiQKiMPsmQXgcfLkyUMPBAC8YI4dO2Z6W6cJEJLk5eUVb5mvr682bNhgV3sWiyXBNgEA9mMYHAC8eBJzktFpJlEfOnRIgYGB2rZtm83yffv20YsAAAAAOAmnCRC+vr4qUKCA+vTpo23btun48eP64YcftGvXLrVr187R5QEAAACQEw1hcnFx0ZgxYzRo0CB17txZN2/eVOHChTVx4kT5+fk5ujwAAAAAcqIAIUk+Pj76/vvvHV0GAAAAgEdwmiFMAAAAAJwfAQIAAACAaQQIAAAAAKYRIAAAAACYRoAAAAAAYBoBAgAAAIBpBAgAAAAAphEgAAAAAJhGgAAAAABgGgECAAAAgGkECAAAAACmESAAAAAAmEaAAAAAAGAaAQIAAACAaQQIAAAAAKYRIAAAAACYRoAAAAAAYBoBAgAAAIBpBAgAAAAAphEgAAAAAJhGgAAAAABgGgECAAAAgGkECAAAAACmESAAAAAAmEaAAAAAAGAaAQIAAACAaQQIAAAAAKYRIAAAAACYRoAAAAAAYBoBAgAAAIBpBAgAAAAAphEgAAAAAJhGgAAAAABgGgECAAAAgGkECAAAAACmESAAAAAAmEaAAAAAAGAaAQIAAACAaQQIAAAAAKYRIAAAAACYRoAAAAAAYBoBAgAAAIBpBAgAAAAAphEgAAAAAJhGgAAAAABgGgECAAAAgGkECAAAAACmESAAAAAAmEaAAAAAAGAaAQIAAACAaSntfaLVatW5c+eUI0cOSdLx48c1e/ZspUyZUnXr1lWePHmSrUgAAAAAzsGuAHH+/Hm1atVK7u7umjdvnsLDw1W/fn3dvn1bkjR16lRNmzZNhQsXTtZiAQAAADiWXUOYhgwZoosXL6pRo0aSpFmzZun27dsaNmyYVq9erSxZsmjEiBHJWigAAAAAx7MrQGzatEnNmzdXvXr1JEmrV69W1qxZ9dZbbylbtmx6//33tWPHjmQtFAAAAIDj2RUgbt26paxZs0qSwsPDdeDAAVWoUMFY7+npqaioqOSpEAAAAIDTsCtAZMuWTUeOHJEkLV++XBaLRZUrVzbW//nnn8qePXvyVAgAAADAadg1ibpmzZoaPXq0zpw5o82bNytLliwKCgrSmTNn9P3332vdunX67LPPkrtWAAAAAA5mV4D46KOPZLFYtHTpUpUoUUI9evRQypQpdfv2bW3dulXt2rVTs2bNkrtWAAAAAA5m930gOnbsqI4dO9os8/Pz019//SU3N7ckFwYAAADA+dgdIBKSIkUKpUiRIjmbBAAAAOBETAWIggULymKxJLrxgwcPJvo5AAAAAJyXqQBRp06deAFi1apVioyMVMWKFZUnTx5ZrVadPn1af/zxh1KnTm3cIwIAAADAi8NUgOjfv7/N4ylTpmjdunWaM2eOcubMabPu3LlzatSokV09FgAAAACcm133gRg/fryaNWsWLzxIUvbs2fXBBx9o1qxZSSrs5MmTCgwM1Ny5c5PUDgAAAIDkY/edqFOmfHTnRXR0tB48eGB3UZGRkerevbvu3r1rdxsAAAAAkp9dAaJ48eKaMmWKLl68GG/dsWPHNHnyZL322mt2FzVy5EilSpXK7ucDAAAAeDrsuoxr165d1aRJE9WoUUOVKlVSjhw59ODBA508eVIbNmyQt7e3evToYVdBW7du1cyZMzV//nwFBwfb1QYAAACAp8OuAOHv769Zs2ZpxIgRWrt2rTHUKHXq1AoNDdUnn3yiV199NdHt3rx5Uz169FCvXr2UJUsWe0oDAAAA8BTZFSDWr1+vwMBAjRgxQlarVdeuXZPFYlH69OmTVEzv3r1VvHhxhYaGJqmdWFarlXkUQBwWi0Wenp6OLgPPuYiICFmtVkeXAQBIRlar1fRVVO0KEJ9++qnq16+vrl27ymKxyMfHx55mbMyfP1/btm3TokWLktxWrMjISG5mB8Th6empwoULO7oMPOdOnjypiIgIR5cBAEhmbm5uprazK0BYrVZlzJjRnqc+0pw5c3TlypV48x6++eYbTZgwQUuWLEl0m66ursqfP38yVQg8/7g/C5JD7M1DAQAvjmPHjpne1q4A8cknn2jMmDHKlCmTSpcurQwZMiT5wGTQoEG6d++ezbJq1aqpU6dOqlGjhl1tWiwWeXl5JakuAIAthsEBwIsnMcfydgWIqVOn6tatW+ratetjizhw4IDpNjNnzpzg8gwZMihbtmyJrhEAAABA8rMrQBQvXlzFixdP5lIAAAAAODu7AsQPP/yQ3HUk6PDhw89kPwAAAADMsStAxDp+/LhWr16tf/75R66ursqaNasqVaqkvHnzJld9AAAAAJyI3QFi0KBB+vnnnxUTE2OzfODAgWrevLndd6IGAAAA4LzsChCzZs3S+PHjFRISonbt2ilv3ryKiYnRiRMn9NNPP2nixIkqUKCA3nnnneSuFwAAAIADudjzpKlTp6ps2bIaPXq0AgIClDp1aqVJk0bFixfXqFGjVKZMGU2ZMiW5awUAAADgYHYFiJMnT6pq1aqPXF+1alWdPHnS7qIAAAAAOCe7AkSqVKkUHh7+yPXh4eFyd3e3uygAAAAAzsmuAFGhQgVNmzZNhw4dirfu4MGDmjp1ql5//fUkFwcAAADAudg1ibpLly7asGGD3n33XVWoUEF58uSRJJ04cUIbN26Ut7e3OnfunJx1AgAAAHACdgWIrFmzatasWRo8eLDWrVundevWSZI8PT31xhtvqHv37sqRI0eyFgoAAADA8ey+D0T27Nk1dOhQxcTE6Nq1a7JarfLx8ZGLi12jogAAAAA8B+w+2t+5c6c+/vhjXb16VRkyZFDGjBn1/fffq127djpy5Ehy1ggAAADASdgVIP7++281adJE27Zt040bN4zl2bJl0759+1S/fn0dPHgw2YoEAAAA4BzsChAjR46Ur6+vfv/9d+XLl89Y3qJFCy1btky5cuXSoEGDkq1IAAAAAM7BrgBx6NAh1atXT97e3vHWeXt767333tPevXuTXBwAAAAA52JXgHB1ddWVK1ceuf727dt2FwQAAADAedkVIMqWLaupU6fq1KlT8dZdvHhRU6dOVZkyZZJaGwAAAAAnY9dlXD/55BP9+eefevvtt1WxYkXlypVLbm5uOnv2rNatWycXFxd16dIluWsFAAAA4GB2BYjcuXNrzpw5Gjp0qNavX681a9ZIengjuQoVKqhr167G3akBAAAAvDjsvpFcrly5NGzYMFmtVl27dk0xMTFKnz69UqRIkZz1AQAAAHAiSbptdFRUlHbt2qXNmzdLkiIiImzuCwEAAADgxWJ3gFi2bJmCg4PVqFEjdevWTUePHtX27dtVqVIljR8/PjlrBAAAAOAk7AoQGzZsULdu3ZQ7d2717NlTVqtVkpQ9e3b5+vpq8ODBWrBgQbIWCgAAAMDx7AoQo0aNkr+/v3755RfVrl3bWJ4vXz5Nnz5dgYGBmjx5crIVCQAAAMA52BUgDh48qJo1a8rFJf7TU6ZMqbffflsnT55McnEAAAAAnIvdd6KOiop65Prr16/L1dXV7qIAAAAAOCe7AkTp0qU1e/Zs3b9/P9668PBwTZ8+XSVLlkxycQAAAACci133gejSpYvq16+vWrVqqWLFirJYLFq9erXWrl2refPm6cGDB+rUqVNy1woAAADAwezqgShQoICmT5+uTJkyacqUKbJarZo6daomT56snDlzatKkSSpUqFBy1woAAADAwey+E3XBggU1depUXbt2TWfPnlVMTIyyZcumTJkyJWd9AAAAAJxIku5ELUnp06dXQECAihcvboSHW7duqVevXkkuDgAAAIBzMd0Dce7cOU2cOFE7d+6UJBUuXFht2rRRrly5bLb7/fff1bdvX12+fFn9+vVL3moBAAAAOJSpAHHw4EE1adJEt2/floeHhzw8PHTgwAEtXbpUM2bMkK+vr9Hr8PvvvytFihRq27bt064dAAAAwDNmagjTiBEjdO/ePQ0ePFi7du3S5s2b9dtvv8nHx0f9+vVTeHi46tWrpxUrVsjf319z5sxRly5dnnbtAAAAAJ4xUwFiz549atCggWrWrGksCwgIUI8ePbR9+3Z16dJFYWFh6t69u2bOnCk/P7+nVjAAAAAAxzE1hOnGjRsqWLBgvOVFixZVdHS0Dh8+rClTpqh48eLJXR8AAAAAJ2KqByIqKkru7u7xlnt4eEiS2rZtS3gAAAAAXgJJvoyrJPn7+ydHMwAAAACcXLIECIvFkhzNAAAAAHBypu8DceLECW3dutVm2a1btyRJhw8fVsqU8ZsqXbp0EssDAAAA4ExMB4gxY8ZozJgxCa778ccfE1x+8OBB+6oCAAAA4JRMBYiPPvroadcBAAAA4DlAgAAAAABgWrJMogYAAADwciBAAAAAADCNAAEAAADANAIEAAAAANNMBYghQ4Zo//79T7sWAAAAAE7OVICYPHmyzT0dChUqpMWLFz+1ogAAAAA4J1OXcfX29tbs2bOVKVMmeXl5yWq16tixY/HuTP1v3IkaAAAAeLGYChCtW7dW//791a5dO0mSxWLR2LFjNXbs2AS3t1qtslgs3IkaAAAAeMGYChDNmzdX+fLldeTIET148EBffPGF3n//fQUGBj7t+gAAAAA4EVMBQpJ8fX3l6+srSZo3b56qV6+ucuXKPbXCAAAAADgf0wEirilTpkiSrl+/rk2bNiksLEyurq7KkiWLXn/9daVOnTpZiwQAAADgHOwKEJI0ffp0DRw4UPfu3ZPVajWWu7u7q0ePHmrcuHGyFAgAAADAedgVIFatWqVvv/1WRYoUUatWrZQ3b15ZrVadOHFCEydOVL9+/ZQ1a1ZVrlw5uesFAAAA4EB2BYhx48apSJEimjFjhlxdXY3lhQoVUrVq1dSgQQONHz+eAAEAAAC8YEzdSO7fDh8+rNq1a9uEh1iurq6qVasWl3AFAAAAXkB2BQh3d3fduXPnketv376tFClS2F0UAAAAAOdkV4AoVaqUpk2bpvDw8HjrLl68qF9//VUlS5ZMcnEAAAAAnItdcyA6d+6s+vXrq3r16qpTp45y584tSTpx4oQWLlyo6OhoffLJJ8lZJwAAAAAnYFeA8PX11eTJk9WvXz9NmzbNZp2/v7969eqlQoUKJUuBAAAAAJyH3feBCAgI0G+//aYrV64oLCxMVqtV2bJlU8aMGZOzPgAAAABOxO4AEStDhgzKkCFDctQCAAAAwMnZNYkaAAAAwMvJqQLElStX9Omnn6ps2bIKDAxU27ZtdezYMUeXBQAAAOD/OVWAaN++vc6ePauffvpJs2fPloeHh5o3b66IiAhHlwYAAABAdgaIQ4cOyWq1Jmsh165dU/bs2dW3b18VLVpU+fLlU4cOHXTp0iUdPXo0WfcFAAAAwD52BYhWrVppyJAhyVpI+vTpNWTIEBUoUECSdPnyZU2YMEGvvvqq8ufPn6z7AgAAAGAfu67CdPfuXWXNmjW5azF89dVX+u233+Tm5qb//ve/8vLysqsdq9Wqu3fvJnN1wPPLYrHI09PT0WXgORcREZHsvdAAAMeyWq2yWCymtrUrQDRt2lSTJk1SkSJFFBAQYE8Tj9WsWTPVr19fv/76qzp27Kjp06erSJEiiW4nMjJSBw8eTPb6gOeVp6enChcu7Ogy8Jw7efIkc9MA4AXk5uZmaju7AsT+/fsVHh6u+vXry8PDQ+nSpZOLi+1oKIvFolWrVtnTvDFkqW/fvtq1a5emTp2qH374IdHtuLq6MvwJiMPsmQXgcfLkyUMPBAC8YBJz5VO7AsT9+/fl7+9vz1Mf6cqVK/rrr79UvXp1pUiRQpLk4uKifPnyKTw83K42LRaL3cOfAAAJYxgcALx4EnOS0a4AMWXKFHue9ljh4eHq1q2bMmTIoHLlykl6OATpwIEDCgkJSfb9AQAAAEi8JN0HIioqSjt37tTSpUt1+fJl3b59Wzdu3LCrrYIFC6pChQrq06ePtm3bpiNHjqhnz566efOmmjdvnpQyAQAAACQTuwPEsmXLFBwcrEaNGqlbt246evSotm/frkqVKmn8+PGJbs9isWjYsGEqW7asOnfurHr16unGjRuaNm3aU73iEwAAAADz7AoQGzZsULdu3ZQ7d2717NnTmEyXPXt2+fr6avDgwVqwYEGi2/X29lbv3r21YcMG7d69WxMmTDDuCwEAAADA8ewKEKNGjZK/v79++eUX1a5d21ieL18+TZ8+XYGBgZo8eXKyFQkAAADAOdgVIA4ePKiaNWvGu3SrJKVMmVJvv/22Tp48meTiAAAAADgXuwKEq6uroqKiHrn++vXrcnV1tbsoAAAAAM7JrgBRunRpzZ49W/fv34+3Ljw8XNOnT1fJkiWTXBwAAAAA52LXfSC6dOmi+vXrq1atWqpYsaIsFotWr16ttWvXat68eXrw4IE6deqU3LUCAAAAcDC7eiAKFCig6dOnK1OmTJoyZYqsVqumTp2qyZMnK2fOnJo0aZIKFSqU3LUCAAAAcDC7eiCkhzd+mzp1qq5du6azZ88qJiZG2bJlU6ZMmZKzPgAAAABOxO4AIUkxMTE6e/aszp07pxQpUsjd3Z0AAQAAALzA7A4Q8+fP16BBg3TlyhWb5dmyZdNXX32lSpUqJbk4AAAAAM7FrgCxaNEiffbZZ8qbN69at26tnDlzKiYmRqdOndKvv/6qjh07aty4cSpfvnxy1wsAAADAgewKED/99JMCAgI0depUubm52axr3Lix6tevr6FDhxIgAAAAgBeMXVdhOnXqlGrXrh0vPEiSp6en3nvvPR0+fDjJxQEAAABwLnYFiJw5c+rkyZOPXH/t2jVlyZLF7qIAAAAAOCe7AkS3bt3022+/acaMGYqJibFZt2rVKv3yyy/65JNPkqVAAAAAAM7D1ByIKlWqJLi8T58+Gjp0qHLkyCGLxaLz58/rypUrSpMmjaZPn64aNWoka7EAAAAAHMtUgMiaNaupZXny5FGePHmSXhUAAAAAp2QqQEyZMuVp1wEAAADgOWDXHAgAAAAALye77gNx48YNDRw4UH/++acuXbokq9UabxuLxaIDBw4kuUAAAAAAzsOuANG3b18tXrxYgYGBKlOmjFKkSJHcdQEAAABwQnYFiD///FMNGjRQ7969k7kcAAAAAM7M7jkQBQsWTM46AAAAADwH7AoQ1atX1++//57ctQAAAABwcnYNYerRo4fatGmj+vXr64033lDGjBllsVjibVenTp2k1gcAAADAidgVILZt26YDBw4oIiJCu3fvTnAbi8VCgAAAAABeMHYFiAEDBsjT01Pdu3dX3rx5uQoTAAAA8JKwK0CcOXNG3bt3V+PGjZO7HgAAAABOzK5J1Hny5NHt27eTuxYAAAAATs6uANGpUydNnjxZ69atU0xMTHLXBAAAAMBJ2TWEadasWXJzc1O7du3k7u6udOnSxZsHYbFYtGrVqmQpEgAAAIBzsCtA3LlzR7lz51bu3LmTuRwAAAAAzsyuADFlypTkrgMAAADAc8CuORAAAAAAXk529UA0bdrU1Ha//PKLPc0DAAAAcFJ2BYhz587FWxYdHa3r16/r/v37ypYtmwoUKJDk4gAAAAA4F7sCxJo1axJcHh0drdWrV6tXr15q1apVkgoDAAAA4HySdQ5EihQpVK1aNdWrV0+DBg1KzqYBAAAAOIGnMok6d+7cOnTo0NNoGgAAAIADJXuAePDggRYuXKgMGTIkd9MAAAAAHCxZr8L04MEDnTx5Ujdv3tTHH3+cpMIAAAAAOJ9kuwqT9HAORN68efX222+rUaNGSSoMAAAAgPNJ1qswAQAAAHixcSdqAAAAAKaZ6oH4z3/+Y1fjH330kV3PAwAAAOCckjVAWCwWm8cECAAAAODFYipArF69+onb3Lp1S8OGDdPatWuVMmXKR16pCQAAAMDzy1SAyJYt22PXL126VP3791d4eLhKlCih3r17y9fXN1kKBAAAAOA87LoKU6wzZ86oT58+2rRpk9KmTat+/frpvffeS67aAAAAADgZuwLEgwcPNG7cOP3000968OCB3nnnHX366adKnz59ctcHAAAAwIkkOkBs2rRJffr00enTp1WgQAF98803KlWq1NOoDQAAAICTMR0gLl++rB9++EFLly6Vh4eHunXrphYtWihlyiSNggIAAADwHDF19D916lQNHz5ct2/fVkhIiHr16qUsWbI87doAAAAAOBlTAaJfv37G92vWrNGaNWue+ByLxaIDBw7YXxkAAAAAp2MqQNSpUyfeTeIAAAAAvHxMBYj+/fs/7ToAAAAAPAdcHF0AAAAAgOcHAQIAAACAaQQIAAAAAKYRIAAAAACYRoAAAAAAYBoBAgAAAIBpBAgAAAAAphEgAAAAAJhGgAAAAABgmlMFiOvXr+vrr79WxYoVVaJECTVs2FDbtm1zdFkAAAAA/p9TBYiuXbtq9+7dGjJkiGbPnq0iRYqoVatWOn78uKNLAwAAACAnChCnT5/Wxo0b9c0336hUqVLKmzevvvzyS2XOnFmLFy92dHkAAAAA5EQBIn369Bo3bpz8/f2NZRaLRVarVTdu3HBgZQAAAABipXR0AbHSpEmjSpUq2SxbtmyZzpw5owoVKtjVptVq1d27d5OjPOCFYLFY5Onp6egy8JyLiIiQ1Wp1dBkAgGRktVplsVhMbes0AeLftm/fri+++EJVqlRRSEiIXW1ERkbq4MGDyVwZ8Pzy9PRU4cKFHV0GnnMnT55URESEo8sAACQzNzc3U9s5ZYBYtWqVunfvrmLFimnIkCF2t+Pq6qr8+fMnY2XA883smQXgcfLkyUMPBAC8YI4dO2Z6W6cLEFOnTtV3332nqlWratCgQaaTUEIsFou8vLySsToAAMPgAODFk5iTjE4ziVqSpk+frr59+6px48YaNmxYksIDAAAAgOTnND0QJ0+e1Pfff6+qVavqww8/1JUrV4x1Hh4e8vb2dmB1AAAAACQnChArVqxQZGSkVq5cqZUrV9qse+edd9S/f38HVQYAAAAgltMEiHbt2qldu3aOLgMAAADAYzjVHAgAAAAAzo0AAQAAAMA0AgQAAAAA0wgQAAAAAEwjQAAAAAAwjQABAAAAwDQCBAAAAADTCBAAAAAATCNAAAAAADCNAAEAAADANAIEAAAAANMIEAAAAABMI0AAAAAAMI0AAQAAAMA0AgQAAAAA0wgQAAAAAEwjQAAAAAAwjQABAAAAwDQCBAAAAADTCBAAAAAATCNAAAAAADCNAAEAAADANAIEAAAAANMIEAAAAABMI0AAAAAAMI0AAQAAAMA0AgQAAAAA0wgQAAAAAEwjQAAA8BTdvHlTZcqUkZ+fn+7fv//I7Q4dOqR27dqpTJkyKlOmjNq0aaNjx44Z6x88eKBhw4apSpUqKlasmJo0aaIDBw7YtLF37141adJEJUqUUMWKFTV8+HBFR0c/tr5FixYpNDRUAQEBeuuttzR58mRZrVZj/ZUrV9S9e3e99tpreu211/Thhx/q9OnTxvqQkBD5+fkl+PX3338n9u0C8BxI6egCAAB4Ud26dUsdO3bU9evXH7tdeHi4WrRooatXr6pIkSKKjIzU+vXrtW/fPi1atEgZM2bUt99+q1mzZilnzpzKkyePtmzZoiZNmmjBggXKnj27Tp8+rQ8++EBRUVEqWbKk9u3bp9GjR+vWrVvq1atXgvvdsGGDunfvLldXV5UuXVq7du3S999/r/v376tt27aSpI4dO2rnzp3KkyePPDw8tHbtWu3fv19LlixR2rRp9frrr+vKlSs2r3nLli1KnTq1cuTIkWzvJQDnQQ8EAABPwdKlS1WrVi1t2bLlidsuX75cV69eVaVKlTR37lwtXLhQ/v7+unr1qlauXKnr169r1qxZ8vHx0aJFizRv3jxVqVJFt2/f1sSJEyVJU6ZM0b1799StWzf98ssvmjJliiwWi6ZPn67Lly8nuN81a9bIxcVFvXv31sSJE/Xtt99KkhYsWCBJOnfunI4dO6acOXMa+82dO7cuXbqkTZs2SZL69u2r0aNHG19ZsmQxlmfNmjXJ7yMA50OAAADgKRg7dqyuXbumjz/++InblitXTj/++KNx1t9iseiVV16R9HAI0ZkzZyRJOXPmlIeHhywWiypUqCBJxjCh2G0KFCggSSpSpIh8fHwUHR2tbdu2Jbjfr7/+Wjt37lStWrWMfUlS2rRpJUnZs2fXtm3bNHfuXLm6uioiIkJ37tyRJKVLly5ee5s2bdKCBQv0+uuvq0aNGk983QCeTwxhAgDgKWjUqJGCg4MVGRmpkSNHPnbbAgUKGAf+knT8+HH9+eefkqSSJUsaZ/VPnjypW7duydvbW4cOHZIkhYWFSZJeffVVSdKePXsUFBSk8+fP68aNG5Kkf/7555H79vDw0IMHD9S4cWPt2LFDPj4++uKLL2y28fb21qxZszRy5EhdunRJ7777rsqWLRuvrdjX+cknnzz29QJ4vhEgAAB4CurXry/p4TCgxDh79qxatWqlyMhIlS5dWuXKlZMkVa1aVStXrlRoaKiyZMmiHTt2SJIxMbtBgwaaPXu2/vOf/2jz5s06fvy4oqKiJEn37t177D7/+ecfo5ciffr0Cc7Z2Lx5sy5evKiUKVPK1dVV9+7dk6enp7F+z5492rFjhwIDA1WsWLFEvWYAzxeGMAEA4CSOHz+uRo0a6fz588qWLZsGDx5srPvhhx9Ut25dRURE6MaNG2rfvr0kGQfxhQsX1ujRo5U/f34dOnRIVapUkb+/vyTJy8vrsfvNmjWrduzYoQkTJuj06dPq0KGDLly4YLPNN998oy1btigoKEgzZszQwIEDbdbPmzdPklSzZs2kvQkAnB49EAAAOIEzZ86oWbNmunTpknLlyqVJkyYpc+bMxnpvb2/98MMPxuNFixZJejgvIlZwcLCCg4ONx2+++aYkPfJqSNHR0QoPD1eGDBmUKlUqVahQQQUKFNDBgwe1c+dOVa9eXbdv31ZERIQyZcokSXrvvff0xx9/xLtE64YNGyRJlStXTsK7AOB5QA8EAAAOdu/ePbVr106XLl1Szpw5NXXqVJsrGEVHR6tu3boqU6aMrl69KklauXKlJOn111+XJM2aNUvBwcHq37+/JOnw4cM6ffq03NzcVLp06QT327hxYwUHB2vZsmWSpKtXr+rs2bOSpEyZMmnDhg0qWbKkmjVrpsjISEkPhyrFro91/vx5nTlzRj4+PsqePXuyvS8AnBM9EAAAPGNLlizRkiVLVKpUKbVs2VIzZ87U8ePHJT0cktS7d29j22rVqqlOnTrKnTu39u/fr/fee0/p06fXvn37lCFDBjVv3lySVKxYMV2+fFmTJ0/W/v37dejQIVmtVrVt21Zp0qSRJA0dOlRHjx5Vw4YNFRQUpKZNm2rnzp368ssvNW/ePB09elS3b99W+fLlVbJkSUVGRqpgwYI6dOiQatSooYwZM2rHjh1KmTKlMYRK+t9E7rgTwQG8uAgQAAA8YydOnNDq1auN+QuxvQnSw56Dw4cPG4/z5s0r6eEchBQpUmj9+vW6du2aqlSpoh49eihjxoySJF9fXw0ZMkTDhw/Xrl27lCVLFn300Udq1qyZ0daOHTu0ZcsWVapUSZKMS62OHz9eu3btUsaMGdWuXTu1b99eFotFbm5uGj9+vIYMGaI///xTR44c0WuvvaZu3bqpePHiRrux95nw8fF5Cu8WAGdjsca9X/0LZO/evZKkokWLOrgSwPlcnTVcUZfDHF0GnjMpM2aTTz0uz5lcvvvuO8XExOirr756pvutU6eO2rdvb8yPAAApccfOzIEAAOAZW7hwoZYsWaJ69eo90/326dNH0dHRCgoKeqb7BfBiIUAAAPCMlShRQkuXLlXBggWf6X4bNGigefPmPfGyrgDwOMyBAADgGXPUlYr8/Pwcsl8ALxZ6IAAAAACYRoAAAAAAYBoBAgAAAIBpBAgAwHMrJuaFvBI5ngE+O4D9mEQNAHhuubhYtHLDYV27edfRpeA5kj6Nl6pWYEI5YC8CBADguXbt5l1dvnrH0WUAwEuDIUwAAAAATCNAAAAAADCNAAEAAADANAIEAAAAANMIEAAAAABMI0AAAAAAMI0AAQAAAMA0AgQAAAAA0wgQAAAAAEwjQAAAAAAwjQABAAAAwDQCBAAAAADTCBAAAAAATCNAAAAAADDNaQPE6NGj1aRJE0eXAQAAACAOpwwQkyZN0ogRIxxdBgAAAIB/SenoAuK6ePGivvzyS23fvl158uRxdDkAAAAA/sWpeiD279+vtGnTauHChSpWrJijywEAAADwL07VAxESEqKQkBBHlwEAAADgEZwqQCQ3q9Wqu3fvOroMwGlYLBZ5eno6ugw85yIiImS1Wh1dBp9nJJmzfJYBZ2C1WmWxWExt+0IHiMjISB08eNDRZQBOw9PTU4ULF3Z0GXjOnTx5UhEREY4ug88zksxZPsuAs3BzczO13QsdIFxdXZU/f35HlwE4DbNnFoDHyZMnj1OcteXzjKRyls8y4AyOHTtmetsXOkBYLBZ5eXk5ugwAeKEwbAgvCj7LwP8k5qSMU12FCQAAAIBzI0AAAAAAMM1phzD179/f0SUAAAAA+Bd6IAAAAACYRoAAAAAAYBoBAgAAAIBpBAgAAAAAphEgAAAAAJhGgAAAAABgGgECAAAAgGkECAAAAACmESAAAAAAmEaAAAAAAGAaAQIAAACAaQQIAAAAAKYRIAAAAACYRoAAAAAAYBoBAgAAAIBpBAgAAAAAphEgAAAAAJhGgAAAAABgGgECAAAAgGkECAAAAACmESAAAAAAmEaAAAAAAGAaAQIAAACAaQQIAAAAAKYRIAAAAACYRoAAAAAAYBoBAgAAAIBpBAgAAAAAphEgAAAAAJhGgAAAAABgGgECAAAAgGkECAAAAACmESAAAAAAmEaAAAAAAGAaAQIAAACAaQQIAAAAAKYRIAAAAGCXq1ev6ptvvlGlSpUUGBiod999V2vWrDHW79q1S/Xq1VPRokVVqVIljRs37pFtrVixQn5+fmrSpMkjt/nss8/k5+eX4NfIkSPjbd+0aVP5+flp/fr1NsvDw8P10UcfKTAwUKVLl9bnn3+u27dv2/EOvJxSOroAAAAAPH+sVqs++ugjbd++XdmyZVORIkW0bds2dejQQRMnTlT+/PnVqlUr3b59W0WLFtWJEyc0ePBgpUqVSo0bN7Zp68qVK/rmm2+euM/ChQvr5s2bNsvWrVunqKgoFSpUyFgWExOjAQMG6O+//35k3bt371bu3Ll1//59zZ07V3fv3tXw4cPtfDdeLvRAAAAAINEOHz6s7du3K3369FqyZImmTp2q5s2by2q16rffftPs2bN1+/Zt1a5dW7Nnz9aoUaMkSZMnT47X1tdff61r1649cZ9NmzbV6NGjja+QkBBFRUWpYcOGeuONNyRJe/fuVePGjTVx4sQE29ixY4d2796tHDlyaPHixVq4cKG8vLy0YsUKXbhwIQnvyMuDAAEAAIBEy5gxo4YOHaqvv/5anp6ekqRXX31V0sMehR07dkiSypQpI0l67bXX5OrqqtOnT+vKlStGO/Pnz9eqVatUpEiRRO3/6tWrGjBggHx8fNS1a1dj+cKFC7Vjxw41adJEmTNnjve82LpKliwpV1dXpUmTRkWLFpXVajXW4fEIEAAAAEi0jBkzqkaNGqpRo4YkKSIiQjNnzpT08OD8/PnzkqT06dNLklKkSCFvb29JMtZduHBB/fr1U65cufTJJ58kav+TJ0/WjRs31KJFC6VJk8ZYXrZsWc2dO1e9evVSypTxR+v/u66439MDYQ4BAgAAAEly7949dejQQSdOnFC6dOnUpEkT3bt3T5JsDuJjv49d9+WXX+rOnTv6/vvv5eHhkaj9zZw5U56enmrQoIHNuipVqjy2N8NMXXg8AgQAAADsdufOHbVu3VqbNm2Sm5ubhg0bJh8fH7m7u0uSoqOjjW2joqIkSZ6enpo+fbo2bNigpk2bqlSpUona5x9//KFr164pKCjIpvfBjCfVhScjQAAAAMAu9+/f14cffqitW7fK09NTY8aMUbly5STJmH9w48YNSQ8P2GOvoJQlSxYtW7ZMkjRp0iT5+fmpadOmkqQtW7bIz89P586de+R+N2zYIEmqXLlyomuOrev69evGsqtXr0r63xwOPB6XcQUAAIBdevfura1bt8rd3V3jx4+36UkoXry4Nm7cqM2bN6tOnTraunWroqKilDt3bvn4+KhEiRLGnAhJunbtmnbs2KF06dKpZMmSj+0NiL08a0BAQKJrLl68uCRp27ZtioqK0r1797R//35ZLBaVKFEi0e29jAgQAAAASLRDhw5p7ty5kqS0adPq559/1s8//yxJypMnj5o0aaJJkyZp3rx5OnHihE6cOCFJatGihSSpS5cuNu39/fffatq0qXx9fTV69GhJ0pIlS7RkyRKVKlVKLVu2lPTwPg7nz59XypQplSdPnkTX/dprr6lIkSLav3+/QkNDdf/+fd25c0c1a9ZM8KpNiI8hTC+ZJUuWKDQ0VEWLFtWbb76pBQsWSJJCQkIeeWfHhG7CIj3sihw6dKiCg4NVvHhxvffee9q4caPNNlFRURoxYoSxTYMGDbRnzx6bbfbv369mzZqpWLFiqlChggYOHGgzLhEAADif33//3fg+PDxcq1evNr62bt2qV199VZMmTVJgYKAOHDggLy8vdevWLd6k58c5ceKEVq9erf379xvLrl27pqioKKVNm1YpUqRIdN0uLi4aO3as3nrrLV24cEE3b95U3bp11bdv30S39bKyWK1Wq6OLeBr27t0rSSpatKiDK3Ee8+fPV8+ePeXu7q7ixYtrx44dioqK0qRJk7RkyRKbazLfunVLW7ZsUerUqbVo0SJlzZo1XntDhgzR2LFj5ePjo/z582vr1q2yWCyaNm2a0QX4+eefa+7cucqQIYNy5sypnTt3Kl26dFq2bJl8fHx0/Phxvffee7p7964CAwN1+vRpXb16VR999JE+/vjjZ/bevGyuzhquqMthji4Dz5mUGbPJp17iLrP4LPy2dKcuX73j6DLwHMnok0rv1wh0dBkw6bvvvlNMTIy++uorR5fyQkvMsTM9EC+JmJgYDR48WJI0bNgw/fLLL+ratat8fHy0bds29e3b1+bOjlmyZJEk9e3bN8HwID28AoLFYtHMmTM1ZcoU1atXTzExMVq0aJEk6fjx45o7d668vLw0b948zZgxQ2+88Ya8vLyMD+l//vMf3b17Vy1atNCMGTM0btw4eXt7a/fu3c/gXQEAAM5s4cKFWrJkierVq+foUhAHcyBeEkeOHFF4eLjc3d0VHBwsSWrZsqUxnjCuTZs2acGCBXr99deNm8MkZNGiRbp165YxAery5cuSHo6DlP53hYTAwEBjTGHsbexjxQ55qlatmqSHqXfbtm32vkwAAPACKVGihJYuXap06dI5uhTEQQ/ES+LMmTOSHh7cDxgwQIGBgTZzIOIaOXKkJJm6I6S3t7f27t2r0NBQrVmzRkWKFDEmR509e1bSwztPtmnTRsWLF1f9+vW1b98+SQ8vnxZ7abeNGzeqQoUKqlChggYPHqzIyMikv2gAAPBcy549O+HBCREgXhJ3796V9HCS06xZsxQQEKCwsDD16NFD69atM7bbs2ePduzYocDAQBUrVsxU2wcPHtSRI0ckSenSpTOu8Ry7z/Xr1+vYsWMqWLCgdu3apebNmys8PFwRERFGG6NHj1aePHkUFRWlcePGadiwYcnxsgEAAJDMCBAvibi3h58wYYImT55sXG1gypQpxrp58+ZJkmrWrGm67Zo1a2rnzp365JNPtHHjRrVv395mn+nTp9eiRYs0Y8YM1a1bV7du3dL8+fONO0FKDy/lNmXKFM2aNUsuLi6aNm2aXtD5/QAAAM81AsRLIu5E6IIFC0r6381XLly4YKxLzJ0d79+/r7CwMKVKlUpeXl5q0qSJJOno0aO6evWqsc8cOXIoderU8faZPn16eXl5SZL8/PyMbX18fBQREaFr167Z/4IBAADwVBAgXhKFChUyxhBu2rRJknTs2DFJUs6cOSVJ58+f15kzZ+Tj46Ps2bM/tr3bt2+rZMmSqlq1qnGr+dgrJ3l6eip16tQqW7assZ/w8PB4+7RYLCpTpowk6a+//pIkXbp0SdevX5e3t7d8fHyS5bUDAODsrDH0usN+z/rzw1WYXhKurq5q166d+vfvr86dOyswMFB79uyRxWIxrsQUFvbwvgAFChRIsI0OHTpIkr755htlzpxZ7777rmbMmKF3331XhQsX1vbt2yVJbdu2lZubm/z9/VW5cmX98ccfqlOnjvLmzautW7cqQ4YMqlOnjiSpffv22rBhgyZOnKjdu3crLCxMUVFRatWq1VN+RwAAcB4WF4surDqoyGt3HV0KnjOu6b306huFnuk+CRAvkRYtWihlypSaNGmSdu3apfz586tTp04qVaqUpP9dhvVRZ/5Xr14tSfr0008lSV9++aVeeeUVzZ8/Xzt37lTu3LnVokULvfPOO8Zzhg4dqkGDBmnx4sU6fPiwKlasqM8//9zoDSlWrJh++uknDRw4UPv27VPWrFnVs2dPNW/e/Cm9CwAAOKfIa3d1//JtR5cBPBF3ooZpN27cUNmyZbVp0yalT5/e0eUgCbgTNezBnajxonDWO1GfnbWdAIFEc8+YWjnqlUxyO9yJGsnu3r17atmyperUqUN4AAAAeIkxhAmmeHh46Ntvv1WRIkUcXQoAAAAciB4ImEZ4AAAAAAECAAAAgGkECAAAAACmESAAAAAAmOZUASImJkYjRoxQUFCQihUrppYtW+r06dOOLksx1hhHl4DnGJ8fAADwInGqqzCNHj1aM2bM0A8//KDMmTNr4MCBatOmjRYvXiw3NzeH1eVicdG03X/q4u0bDqsBz6fMqdOqcbEgR5cBAACQbJwmQDx48EA///yzPv30U1WqVEnSw7sYBwUFaeXKlapZs6ZD67t4+4bCbl51aA0AAACAoznNEKZDhw7pzp07Klu2rLEsTZo0Kly4sLZu3erAygAAAADEcpoeiAsXLkiSsmTJYrP8lVde0fnz5xPdXmRkpKxWq/bs2ZPk2iwWi8p5ZFa0W6Ykt4WXSwoXF+3du1dWq9XRpRgsFoticr0m5WBuBhLJxUVhTvh5zp3JqpwZPB1dCp4jLi5Wp/y/OTqXRdYcqR1dCp4zt10sup4Mn+fIyEhZLBZT2zpNgIiIiJCkeHMd3N3ddeNG4ucexL4BZt+IJ0nt5pEs7eDllFyfw+Ti4skfKNjP2T7Pnh6uji4Bzyln+yyn8OSzDPsl9fNssVievwDh4fHwAP3BgwfG95J0//59eXom/sxSYGBgstUGAAAA4CGnmQMRO3QpPDzcZnl4eLheffVVR5QEAAAA4F+cJkAULFhQqVOn1t9//20su3nzpg4cOKBSpUo5sDIAAAAAsZxmCJObm5s++OADDRo0SD4+PsqWLZsGDhyoV199VVWrVnV0eQAAAADkRAFCkjp16qSoqCj16tVL9+7dU+nSpTVhwgSH3kQOAAAAwP9YrM50DTMAAAAATs1p5kAAAAAAcH4ECAAAAACmESAAAAAAmEaAAAAAAGAaAQIAAACAaQQIAAAAAKYRIJAsRo8erSZNmji6DMAu169f19dff62KFSuqRIkSatiwobZt2+bosgC7XLlyRZ9++qnKli2rwMBAtW3bVseOHXN0WUCSnDx5UoGBgZo7d66jS4EIEEgGkyZN0ogRIxxdBmC3rl27avfu3RoyZIhmz56tIkWKqFWrVjp+/LijSwMSrX379jp79qx++uknzZ49Wx4eHmrevLkiIiIcXRpgl8jISHXv3l137951dCn4fwQI2O3ixYtq3bq1hg8frjx58ji6HMAup0+f1saNG/XNN9+oVKlSyps3r7788ktlzpxZixcvdnR5QKJcu3ZN2bNnV9++fVW0aFHly5dPHTp00KVLl3T06FFHlwfYZeTIkUqVKpWjy0AcBAjYbf/+/UqbNq0WLlyoYsWKObocwC7p06fXuHHj5O/vbyyzWCyyWq26ceOGAysDEi99+vQaMmSIChQoIEm6fPmyJkyYoFdffVX58+d3cHVA4m3dulUzZ87Ujz/+6OhSEEdKRxeA51dISIhCQkIcXQaQJGnSpFGlSpVsli1btkxnzpxRhQoVHFQVkHRfffWVfvvtN7m5uem///2vvLy8HF0SkCg3b95Ujx491KtXL2XJksXR5SAOeiAAII7t27friy++UJUqVQjIeK41a9ZMc+bMUa1atdSxY0ft37/f0SUBidK7d28VL15coaGhji4F/0KAAID/t2rVKrVq1UoBAQEaMmSIo8sBkiR//vzy9/dX3759lT17dk2dOtXRJQGmzZ8/X9u2bVPv3r0dXQoSQIAAAElTp07Vxx9/rIoVK+qnn36Sh4eHo0sCEu3KlStavHixoqOjjWUuLi7Kly+fwsPDHVgZkDhz5szRlStXFBwcrMDAQAUGBkqSvvnmG9WsWdPB1YE5EABeetOnT1ffvn3VpEkTffHFF3Jx4dwKnk/h4eHq1q2bMmTIoHLlykl6eAnMAwcOMCQPz5VBgwbp3r17NsuqVaumTp06qUaNGg6qCrEIEABeaidPntT333+vqlWr6sMPP9SVK1eMdR4eHvL29nZgdUDiFCxYUBUqVFCfPn3Ur18/pUmTRmPGjNHNmzfVvHlzR5cHmJY5c+YEl2fIkEHZsmV7xtXg3wgQAF5qK1asUGRkpFauXKmVK1farHvnnXfUv39/B1UGJJ7FYtGwYcM0ePBgde7cWbdu3VKpUqU0bdo0Zc2a1dHlAXhBWKxWq9XRRQAAAAB4PjDQFwAAAIBpBAgAAAAAphEgAAAAAJhGgAAAAABgGgECAAAAgGkECAAAAACmESAAAAAAmEaAAAAAAGAaAQIAnNSDBw80btw41apVS8WLF1eJEiVUt25d/fzzz3rw4IGjy3ukzz77TH5+fjbLHjx4oIsXLya57b///lt+fn4aOXJkkttKbnPnzpWfn5/+/vtvR5cCAE8VAQIAnFBUVJRatWqlkSNHqlixYvr000/VuXNnZc+eXQMGDFCLFi2cNkTUr19fAwYMMB6HhYUpNDRUGzdudGBVAIDkktLRBQAA4lu2bJm2bNmikSNHqlq1asbypk2bavz48Ro4cKDmzJmjhg0bOrDKhAUGBiowMNB4fO7cOZ06dcpxBQEAkhU9EADghHbu3ClJev311+Ota9y4sVxdXY1tAAB4lggQAOCEUqdOLUmaOXNmvHWenp7asWOHzTAhSTp69Kg6dOigUqVKqVixYmrQoIH+/PNPY/24cePk5+en/fv3x2uzWrVqaty4sem2JKlJkyZq1aqVhg4dqsDAQJUrV04HDx60mQMxd+5cNW3aVJL0+eefy8/PTydOnJCfn1+8+iVp6NChKly4sK5cuWL2rXqke/fuaejQoQoJCZG/v7+qVKmi4cOHG0O/wsPDVahQIfXr1y/ec0ePHi0/Pz+dPXvWVFsA8DIhQACAEwoNDZWrq6t+/PFHVa9eXUOGDNGmTZt0//59SZKbm5vN9ocOHdL777+v48eP68MPP1SXLl0UFRWltm3baunSpUabFovFeBxr3759On36tEJDQ023FWvHjh1aunSpunfvrrp168rX19dmfenSpdWuXTtJ/5sbkTdvXhUpUkTLly+P97qXLl2qcuXKKUOGDEl496To6Gi1bdtWEydOVEhIiL788kuVLVtWY8aMUadOnWS1WvXKK6+obNmyWr58uWJiYmyev2zZMhUvXlw5cuQw1RYAvFSsAACn9Mcff1jLlStn9fX1Nb4CAgKsnTt3th4/ftxm28aNG1vfeOMN6507d4xlkZGR1kaNGlnLly9vvX//vtVqtVo/+OADa0hIiM1zf/zxR2uRIkWs165dS3Rbvr6+1p07d9q017NnT6uvr6/xePPmzVZfX1/rnDlzjGUTJ060+vr6Wnft2mUs2717t9XX19c6d+7cR74nsW2NGDHicW+ddfbs2VZfX1/r+vXrbZbPmDHD6uvra125cqXVarVa58yZY/X19bX+/fffxjZHjx61+vr6WqdMmWJXW5s3b35sbQDwvKMHAgCcVHBwsP744w8NHTpUtWvXVqZMmXTv3j0tXbpUtWvX1ubNmyVJV69e1datW1WpUiXdu3dPV69e1dWrV3Xz5k1VrVpVly9f1t69eyU97IU4d+6c9uzZI0myWq1avny5goKClC5dukS1JUkeHh4KCAhI9GurUaOGXFxcbHo0li5dKnd3d1WtWjUpb5skaeXKlfLx8VGRIkWM13D16lVVqlRJKVKk0Nq1ayU9HLrl7u6uZcuWGc9dsmSJUqZMqerVqyeqLQB4WXAVJgBwYu7u7qpRo4Zq1Kgh6eHwovHjx2vRokXq3bu3li9fbozTnzJliqZMmZJgO+fPn5ckvfXWW/r222+1bNkyBQQEaNeuXQoLC1P37t0lKVFtSVK6dOnk4pL4c1GvvPKKypQpo+XLl+uzzz6T9HDYUHBwsDH/IylOnz6tq1evqly5cgmuj30NqVOnVuXKlfX777+rV69eSpEihZYuXary5csbw6jMtgUALwsCBAA4mbt372rs2LEqUqSIzSVcJalgwYIaNGiQbty4ofXr1+vatWvG+P3GjRvrjTfeSLDN/PnzS5LSpEmjSpUqafny5erRo4eWLl2qVKlSKSQkRJIS1ZYkpUiRwu7XGRoaqi+++EI7duyQ1WrVhQsX1KtXL7vbiysmJka5c+fWN998k+D6NGnS2NSxfPlybdmyRenSpdOpU6fUoUMHu9oCgJcBAQIAnIy7u7smTJigwMDAeAEiVv78+fXnn3/Kw8ND2bJlk/TwYL58+fI22x07dkznzp2Tp6ensaxWrVpatWqV9u3bpxUrVqhq1ary8PCQpES3lRRvvvmm+vTpozVr1igmJsYIN8khe/bs2rdvn8qWLWvTQxIZGamVK1fq1VdfNZZVqlRJ6dKl0+rVq+Xl5SVPT0+b8JSYtgDgZcAcCABwMilSpFCNGjW0ZcsWLViwIN7669eva8WKFSpfvrw8PT31yiuvyN/fX/PmzdPFixeN7SIjI/XFF1+oU6dOioqKMpZXrlxZ3t7eGjlypC5evGhcfUlSotsy+3okxbvSUerUqRUcHKz169dr/fr1qlq1aryrS9krJCRE169f16+//mqzfMaMGerSpYv++usvY5mrq6vefPNNrV27VitXrlSVKlWUKlUqu9oCgJcBPRAA4IQ+++wz7dmzRz169NDChQsVFBSk1KlT68yZM5o7d64iIyP19ddfG9v36tVLzZo107vvvquGDRsqXbp0WrJkiXbv3q1u3bopffr0xrZubm6qVq2a5syZo4wZM8Yb25+YtsyI3X7hwoWyWq165513lDLlwz8/tWrVUseOHY39mvXHH3/o0qVL8ZZnyZJF7du3V7169TRv3jz17dtX+/fvV0BAgI4cOaKZM2eqSJEiqlu3rs3zatWqZdxzo2fPnjbrEtsWALzoCBAA4IR8fHw0d+5cTZo0SatXr9aoUaMUERGhV155RVWrVlX79u31yiuvGNsHBgbq119/1ciRIzVx4kRFRUUpT5486t+/v95555147YeGhmrOnDmqXr16vHkMiW3rSfLly6cmTZpo7ty52rt3r8qUKaOcOXNKkipWrKi0adPKzc1NZcqUMd3m/v37E7whXsGCBdW+fXu5ublp0qRJGjVqlFasWKGFCxfqlVdeUcOGDdWxY8d4w7BKliypbNmy6c6dO/Hu/p3YtgDgRWexWrkDDgDAMSIjI1WhQgW98847xtWYAADOjTkQAACHWbp0qa5fv84wIAB4jjCECQDwzP3888/asWOH1q9fr4oVK8rX19fRJQEATKIHAgDwzEVHR2vDhg0qVqyYvvvuO0eXAwBIBOZAAAAAADCNHggAAAAAphEgAAAAAJhGgAAAAABgGgECAAAAgGkECAAAAACmESAAAAAAmEaAAAAAAGAaAQIAAACAaQQIAAAAAKb9H0gSKjiqc5PQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of the target variable\n",
    "target_column = 'Severity'  # Replace with your actual target column name\n",
    "class_distribution = df[target_column].value_counts()\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(class_distribution)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare data\n",
    "target_column = 'Severity'\n",
    "class_distribution = df[target_column].value_counts().sort_index()\n",
    "class_df = pd.DataFrame({\n",
    "    'Severity': class_distribution.index,\n",
    "    'Count': class_distribution.values\n",
    "})\n",
    "\n",
    "# Set the style and palette\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "barplot = sns.barplot(data=class_df, x='Severity', y='Count', hue='Severity', palette=palette, legend=False)\n",
    "\n",
    "# Annotate the bars\n",
    "for i, count in enumerate(class_df['Count']):\n",
    "    barplot.text(i, count + max(class_df['Count'])*0.01, f'{count:,}', \n",
    "                 ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(\"Class Distribution of Target Variable\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Severity Level\", fontsize=13)\n",
    "plt.ylabel(\"Number of Records\", fontsize=13)\n",
    "plt.xticks(fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution After Undersampling:\n",
      "Severity\n",
      "1    67366\n",
      "2    67366\n",
      "3    67366\n",
      "4    67366\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Step 7: Separate features and target\n",
    "target_column = 'Severity'  # Replace with your actual target column name\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "\n",
    "# Define the undersampler\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Apply undersampling\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(\"\\nClass Distribution After Undersampling:\")\n",
    "print(pd.Series(y_resampled).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[12862   248   244   120]\n",
      " [  362  8445  2494  2061]\n",
      " [  605  1075 10251  1536]\n",
      " [  188  1617   681 11104]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.95      0.94     13474\n",
      "           2       0.74      0.63      0.68     13362\n",
      "           3       0.75      0.76      0.76     13467\n",
      "           4       0.75      0.82      0.78     13590\n",
      "\n",
      "    accuracy                           0.79     53893\n",
      "   macro avg       0.79      0.79      0.79     53893\n",
      "weighted avg       0.79      0.79      0.79     53893\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "0.7916055888519845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Step 8: Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled,shuffle = True, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 9: Train a Random Forest model\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 10: Make predictions\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Step 11: Evaluate the model\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.94      0.91     13474\n",
      "           2       0.73      0.50      0.60     13362\n",
      "           3       0.72      0.71      0.72     13467\n",
      "           4       0.67      0.83      0.74     13590\n",
      "\n",
      "    accuracy                           0.75     53893\n",
      "   macro avg       0.75      0.75      0.74     53893\n",
      "weighted avg       0.75      0.75      0.74     53893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train a Gradient Boosting model\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "print(\"\\nGradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imbalanced-learn in c:\\programdata\\anaconda3\\lib\\site-packages (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     13474\n",
      "           1       0.75      0.62      0.68     13362\n",
      "           2       0.74      0.76      0.75     13467\n",
      "           3       0.74      0.81      0.77     13590\n",
      "\n",
      "    accuracy                           0.79     53893\n",
      "   macro avg       0.79      0.79      0.78     53893\n",
      "weighted avg       0.79      0.79      0.78     53893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Adjust y_train and y_test to start from 0 if necessary\n",
    "y_train_adjusted = y_train - 1\n",
    "y_test_adjusted = y_test - 1\n",
    "\n",
    "# Train an XGBoost model without the use_label_encoder parameter\n",
    "xgb_clf = XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
    "xgb_clf.fit(X_train, y_train_adjusted)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nXGBoost Classification Report:\")\n",
    "print(classification_report(y_test_adjusted, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.79      0.71     13474\n",
      "           2       0.54      0.36      0.43     13362\n",
      "           3       0.54      0.64      0.59     13467\n",
      "           4       0.58      0.53      0.55     13590\n",
      "\n",
      "    accuracy                           0.58     53893\n",
      "   macro avg       0.58      0.58      0.57     53893\n",
      "weighted avg       0.58      0.58      0.57     53893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Step 7: Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "# Step 8: Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 9: Train a Logistic Regression model\n",
    "lr_clf = LogisticRegression(max_iter=500, random_state=42)  # Increased max_iter\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = lr_clf.predict(X_test)\n",
    "print(\"\\nLogistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.13.1)\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 15.2 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3327\n",
      "[LightGBM] [Info] Number of data points in the train set: 215571, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score -1.386308\n",
      "[LightGBM] [Info] Start training from score -1.384232\n",
      "[LightGBM] [Info] Start training from score -1.386178\n",
      "[LightGBM] [Info] Start training from score -1.388463\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.95      0.93     13474\n",
      "           2       0.74      0.61      0.67     13362\n",
      "           3       0.74      0.75      0.75     13467\n",
      "           4       0.73      0.82      0.77     13590\n",
      "\n",
      "    accuracy                           0.78     53893\n",
      "   macro avg       0.78      0.78      0.78     53893\n",
      "weighted avg       0.78      0.78      0.78     53893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm_clf = LGBMClassifier(random_state=42)\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "y_pred = lgbm_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2.8-cp312-cp312-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.3)\n",
      "Downloading catboost-1.2.8-cp312-cp312-win_amd64.whl (102.4 MB)\n",
      "   ---------------------------------------- 0.0/102.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.1/102.4 MB 13.0 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 5.0/102.4 MB 13.1 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 8.4/102.4 MB 13.7 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 11.8/102.4 MB 14.2 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 14.4/102.4 MB 13.9 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 17.6/102.4 MB 13.8 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 20.7/102.4 MB 13.9 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 23.9/102.4 MB 14.0 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 26.5/102.4 MB 13.9 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 28.8/102.4 MB 13.6 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 31.5/102.4 MB 13.6 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 34.3/102.4 MB 13.5 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 37.2/102.4 MB 13.4 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 40.1/102.4 MB 13.4 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 42.5/102.4 MB 13.5 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 44.6/102.4 MB 13.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 47.7/102.4 MB 13.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 50.9/102.4 MB 13.2 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 52.4/102.4 MB 12.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 55.1/102.4 MB 12.8 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 57.9/102.4 MB 12.9 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 60.6/102.4 MB 12.8 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 63.7/102.4 MB 12.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 66.8/102.4 MB 13.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 69.7/102.4 MB 13.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 72.6/102.4 MB 13.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 75.2/102.4 MB 13.0 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 78.1/102.4 MB 13.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 80.7/102.4 MB 13.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 83.6/102.4 MB 13.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 86.2/102.4 MB 13.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 88.9/102.4 MB 13.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 91.8/102.4 MB 13.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 94.6/102.4 MB 13.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 97.0/102.4 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.9/102.4 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  102.2/102.4 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  102.2/102.4 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------- 102.4/102.4 MB 12.6 MB/s eta 0:00:00\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.2.8 graphviz-0.20.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat_clf = CatBoostClassifier(random_state=42, verbose=0)\n",
    "cat_clf.fit(X_train, y_train)\n",
    "y_pred = cat_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "# Create and fit the Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('xgb', XGBClassifier(random_state=42, eval_metric='mlogloss')),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42))\n",
    "], voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Access feature importances from the Random Forest model\n",
    "importances = voting_clf.estimators_[0].feature_importances_  # Example for Random Forest\n",
    "plt.barh(range(len(importances)), importances)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create a Voting Classifier with Random Forest, XGBoost, and Gradient Boosting\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('xgb', XGBClassifier(random_state=42, eval_metric='mlogloss')),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42))\n",
    "], voting='soft')\n",
    "\n",
    "# Fit the Voting Classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "# Step 4: Create new features\n",
    "# Create all new features in a separate DataFrame\n",
    "new_features = pd.DataFrame()\n",
    "\n",
    "# Distance binning\n",
    "new_features['Distance_Category'] = pd.cut(\n",
    "    X_resampled['Distance(mi)'], bins=[0, 1, 5, 10, 50], labels=['Short', 'Medium', 'Long', 'Very Long']\n",
    ")\n",
    "\n",
    "# Extreme weather conditions\n",
    "new_features['Extreme_Temperature'] = (X_resampled['Temperature(F)'] > 100) | (X_resampled['Temperature(F)'] < 32)\n",
    "new_features['High_Wind'] = X_resampled['Wind_Speed(mph)'] > 30\n",
    "\n",
    "# Time-based features\n",
    "X_resampled['Start_Time'] = pd.to_datetime(X_resampled['Start_Time'])\n",
    "new_features['Start_Hour'] = X_resampled['Start_Time'].dt.hour\n",
    "new_features['Start_Day'] = X_resampled['Start_Time'].dt.dayofweek\n",
    "new_features['Is_Weekend'] = new_features['Start_Day'].isin([5, 6])\n",
    "\n",
    "# Interaction features\n",
    "new_features['Temp_Humidity_Interaction'] = X_resampled['Temperature(F)'] * X_resampled['Humidity(%)']\n",
    "\n",
    "# Step 5: Concatenate new features with the original DataFrame\n",
    "X_resampled = pd.concat([X_resampled.reset_index(drop=True), new_features.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Step 6: Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "numerical_features = ['Distance(mi)', 'Temperature(F)', 'Humidity(%)', 'Wind_Speed(mph)']\n",
    "X_resampled[numerical_features] = scaler.fit_transform(X_resampled[numerical_features])\n",
    "\n",
    "\n",
    "# Step 10: Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 11: Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Step 3: Create new features\n",
    "X_resampled['Distance_Category'] = pd.cut(\n",
    "    X_resampled['Distance(mi)'], bins=[0, 1, 5, 10, 50], labels=['Short', 'Medium', 'Long', 'Very Long']\n",
    ")\n",
    "X_resampled['Extreme_Temperature'] = (X_resampled['Temperature(F)'] > 100) | (X_resampled['Temperature(F)'] < 32)\n",
    "X_resampled['High_Wind'] = X_resampled['Wind_Speed(mph)'] > 30\n",
    "X_resampled['Start_Hour'] = pd.to_datetime(X_resampled['Start_Time']).dt.hour\n",
    "X_resampled['Start_Day'] = pd.to_datetime(X_resampled['Start_Time']).dt.dayofweek\n",
    "X_resampled['Is_Weekend'] = X_resampled['Start_Day'].isin([5, 6])\n",
    "X_resampled['Temp_Humidity_Interaction'] = X_resampled['Temperature(F)'] * X_resampled['Humidity(%)']\n",
    "\n",
    "# Step 4: Drop low-importance features\n",
    "low_importance_features = [\n",
    "    'Weather_Condition_Heavy Rain Showers',\n",
    "    'Weather_Condition_Heavy Thunderstorms with Small Hail',\n",
    "    'Weather_Condition_Light Snow Grains',\n",
    "    # Add other features with zero importance\n",
    "]\n",
    "X_resampled = X_resampled.drop(columns=low_importance_features, errors='ignore')\n",
    "\n",
    "# Step 5: Normalize numerical features\n",
    "numerical_features = ['Distance(mi)', 'Temperature(F)', 'Humidity(%)', 'Wind_Speed(mph)']\n",
    "scaler = MinMaxScaler()\n",
    "X_resampled[numerical_features] = scaler.fit_transform(X_resampled[numerical_features])\n",
    "\n",
    "# Step 6: Encode categorical features\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')  # Use one-hot encoding\n",
    "encoded_categories = encoder.fit_transform(X_resampled[['Distance_Category']])\n",
    "encoded_category_df = pd.DataFrame(\n",
    "    encoded_categories, \n",
    "    columns=encoder.get_feature_names_out(['Distance_Category'])\n",
    ")\n",
    "\n",
    "# Add encoded columns to the dataset and drop the original categorical column\n",
    "X_resampled = pd.concat([X_resampled.reset_index(drop=True), encoded_category_df], axis=1)\n",
    "X_resampled = X_resampled.drop(columns=['Distance_Category'])\n",
    "\n",
    "# Step 7: Prepare data for modeling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 8: Train Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Step 9: Evaluate model\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 10: Get feature importance\n",
    "log_reg_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': np.abs(log_reg.coef_[0])\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Logistic Regression Feature Importance:\")\n",
    "print(log_reg_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Step 1: Separate features and target\n",
    "target_column = 'Severity'  # Replace with your actual target column name\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Step 2: Handle class imbalance (undersampling)\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
    "\n",
    "# Step 3: Feature Engineering (optimized to avoid fragmentation)\n",
    "new_features = pd.DataFrame({\n",
    "    'Distance_Category': pd.cut(\n",
    "        X_resampled['Distance(mi)'], bins=[0, 1, 5, 10, 50], labels=['Short', 'Medium', 'Long', 'Very Long']\n",
    "    ),\n",
    "    'Extreme_Temperature': (X_resampled['Temperature(F)'] > 100) | (X_resampled['Temperature(F)'] < 32),\n",
    "    'High_Wind': X_resampled['Wind_Speed(mph)'] > 30,\n",
    "    'Start_Hour': pd.to_datetime(X_resampled['Start_Time']).dt.hour,\n",
    "    'Start_Day': pd.to_datetime(X_resampled['Start_Time']).dt.dayofweek,\n",
    "    'Is_Weekend': pd.to_datetime(X_resampled['Start_Time']).dt.dayofweek.isin([5, 6]),\n",
    "    'Temp_Humidity_Interaction': X_resampled['Temperature(F)'] * X_resampled['Humidity(%)']\n",
    "})\n",
    "\n",
    "# Concatenate new features with the original DataFrame\n",
    "X_resampled = pd.concat([X_resampled, new_features], axis=1)\n",
    "\n",
    "# Step 4: Drop low-importance features\n",
    "low_importance_features = [\n",
    "    'Weather_Condition_Heavy Rain Showers',\n",
    "    'Weather_Condition_Heavy Thunderstorms with Small Hail',\n",
    "    'Weather_Condition_Light Snow Grains',\n",
    "    # Add other features with zero importance\n",
    "]\n",
    "X_resampled = X_resampled.drop(columns=low_importance_features, errors='ignore')\n",
    "\n",
    "# Step 5: Normalize numerical features\n",
    "numerical_features = ['Distance(mi)', 'Temperature(F)', 'Humidity(%)', 'Wind_Speed(mph)']\n",
    "scaler = MinMaxScaler()\n",
    "X_resampled[numerical_features] = scaler.fit_transform(X_resampled[numerical_features])\n",
    "\n",
    "# Step 6: Encode categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # Updated to use sparse_output\n",
    "encoded_categories = encoder.fit_transform(X_resampled[['Distance_Category']])\n",
    "encoded_category_df = pd.DataFrame(\n",
    "    encoded_categories, \n",
    "    columns=encoder.get_feature_names_out(['Distance_Category'])\n",
    ")\n",
    "\n",
    "# Add encoded columns to the dataset and drop the original categorical column\n",
    "X_resampled = pd.concat([X_resampled.reset_index(drop=True), encoded_category_df], axis=1)\n",
    "X_resampled = X_resampled.drop(columns=['Distance_Category'])\n",
    "\n",
    "# Step 7: Adjust target variable to start from 0\n",
    "y_resampled = y_resampled - y_resampled.min()\n",
    "\n",
    "# Step 8: Prepare data for modeling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 9: Train XGBoost Classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,  # Number of trees\n",
    "    max_depth=6,       # Maximum depth of each tree\n",
    "    learning_rate=0.1, # Learning rate\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 10: Evaluate the model\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 11: Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"XGBoost Feature Importance:\")\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Adjust target variable to start from 0\n",
    "y_resampled = y_resampled - y_resampled.min()\n",
    "\n",
    "# Define a function to perform RFECV and train the model\n",
    "def perform_rfecv_and_train(model, model_name, X, y, step=2, cv=3):\n",
    "    print(f\"\\nPerforming RFECV for {model_name}...\")\n",
    "    \n",
    "    # Step 1: Initialize RFECV\n",
    "    rfecv = RFECV(\n",
    "        estimator=model,\n",
    "        step=step,  # Number of features to remove at each iteration\n",
    "        cv=StratifiedKFold(cv),  # Cross-validation folds\n",
    "        scoring='accuracy',  # Metric to evaluate performance\n",
    "        n_jobs=-1  # Use all available cores\n",
    "    )\n",
    "    \n",
    "    # Step 2: Fit RFECV to the data\n",
    "    rfecv.fit(X, y)\n",
    "    \n",
    "    # Step 3: Get selected features\n",
    "    selected_features = X.columns[rfecv.support_]\n",
    "    print(f\"Optimal Number of Features for {model_name}: {rfecv.n_features_}\")\n",
    "    print(f\"Selected Features for {model_name}: {list(selected_features)}\")\n",
    "    \n",
    "    # Step 4: Train and evaluate the model with selected features\n",
    "    X_selected = X[selected_features]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\nClassification Report for {model_name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "# Step 5: Perform RFECV and train models\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_selected_features = perform_rfecv_and_train(rf_model, \"Random Forest\", X_resampled, y_resampled, step=2, cv=3)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_selected_features = perform_rfecv_and_train(xgb_model, \"XGBoost\", X_resampled, y_resampled, step=2, cv=3)\n",
    "\n",
    "# CatBoost\n",
    "catboost_model = CatBoostClassifier(random_state=42, verbose=0)\n",
    "catboost_selected_features = perform_rfecv_and_train(catboost_model, \"CatBoost\", X_resampled, y_resampled, step=2, cv=3)\n",
    "\n",
    "# Step 6: Compare Selected Features\n",
    "common_selected_features = set(rf_selected_features) & set(xgb_selected_features) & set(catboost_selected_features)\n",
    "print(f\"\\nCommon Selected Features Across Models: {list(common_selected_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Use the common selected features\n",
    "X_reduced = X_resampled[['Astronomical_Twilight', 'Start_Lat', 'State_NC', 'State_TX', 'Distance(mi)', \n",
    " 'State_GA', 'Traffic_Signal', 'Start_Lng', 'Weather_Timestamp', 'Junction', \n",
    " 'State_CA', 'ID', 'End_Time', 'State_MN', 'Start_Time', 'End_Lng', 'Stop', \n",
    " 'Crossing', 'State_SC', 'End_Lat']]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Use the common selected features\n",
    "X_reduced = X_resampled[['Astronomical_Twilight', 'Start_Lat', 'State_NC', 'State_TX', 'Distance(mi)', \n",
    " 'State_GA', 'Traffic_Signal', 'Start_Lng', 'Weather_Timestamp', 'Junction', \n",
    " 'State_CA', 'ID', 'End_Time', 'State_MN', 'Start_Time', 'End_Lng', 'Stop', \n",
    " 'Crossing', 'State_SC', 'End_Lat']]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Use the common selected features\n",
    "X_reduced = X_resampled[['Astronomical_Twilight', 'Start_Lat', 'State_NC', 'State_TX', 'Distance(mi)', \n",
    " 'State_GA', 'Traffic_Signal', 'Start_Lng', 'Weather_Timestamp', 'Junction', \n",
    " 'State_CA', 'ID', 'End_Time', 'State_MN', 'Start_Time', 'End_Lng', 'Stop', \n",
    " 'Crossing', 'State_SC', 'End_Lat']]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the CatBoost model\n",
    "catboost_model = CatBoostClassifier(random_state=42, verbose=0)\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = catboost_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"CatBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Perform Randomized Search\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Number of parameter settings to sample\n",
    "    cv=3,       # 3-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "print(\"Best Parameters for Random Forest:\", rf_random_search.best_params_)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "best_rf_model = rf_random_search.best_estimator_\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "print(\"Tuned Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],  # Number of trees\n",
    "    'max_depth': [3, 5, 7, 10],  # Maximum depth of a tree\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Step size shrinkage\n",
    "    'subsample': [0.6, 0.8, 1.0],  # Fraction of samples used for training each tree\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],  # Fraction of features used for training each tree\n",
    "    'min_child_weight': [1, 3, 5],  # Minimum sum of instance weight needed in a child\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],  # Minimum loss reduction required to make a split\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier without the use_label_encoder parameter\n",
    "xgb_model = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "xgb_random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Number of parameter settings to sample\n",
    "    scoring='accuracy',  # Metric to optimize\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,  # Print progress\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the data\n",
    "xgb_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters for XGBoost:\", xgb_random_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", xgb_random_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_xgb_model = xgb_random_search.best_estimator_\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "print(\"Classification Report for Tuned XGBoost:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the parameter grid for CatBoost (with subsample and bootstrap_type)\n",
    "param_grid = {\n",
    "    'iterations': [100, 200, 300, 400, 500],  # Number of boosting iterations\n",
    "    'depth': [3, 4, 5, 6, 7, 8],  # Depth of the trees\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Learning rate\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],  # L2 regularization coefficient\n",
    "    'subsample': [0.6, 0.8, 1.0],  # Fraction of samples used for training each tree\n",
    "    'colsample_bylevel': [0.6, 0.8, 1.0],  # Fraction of features used for training each tree\n",
    "    'bootstrap_type': ['Bernoulli'],  # Set bootstrap type to Bernoulli\n",
    "}\n",
    "\n",
    "# Initialize the CatBoost classifier\n",
    "catboost_model = CatBoostClassifier(random_state=42, verbose=0)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "catboost_random_search = RandomizedSearchCV(\n",
    "    estimator=catboost_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Number of parameter settings to sample\n",
    "    scoring='accuracy',  # Metric to optimize\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,  # Print progress\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the data\n",
    "catboost_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters for CatBoost:\", catboost_random_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", catboost_random_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_catboost_model = catboost_random_search.best_estimator_\n",
    "y_pred = best_catboost_model.predict(X_test)\n",
    "print(\"Classification Report for Tuned CatBoost:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, f1_score, precision_recall_curve, average_precision_score\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataset\n",
    "# Replace this with your actual data loading\n",
    "# X, y = load_your_data()\n",
    "\n",
    "# Example: Create a sample dataset (uncomment and replace with your data)\n",
    "# X = pd.DataFrame(np.random.rand(1000, 10))  # 1000 samples, 10 features\n",
    "# y = np.random.randint(-1, 4, size=1000)  # Class labels from -1 to 3\n",
    "\n",
    "# Check the unique values in y\n",
    "print(\"Unique values in y before relabeling:\", np.unique(y))\n",
    "\n",
    "# Ensure all labels are non-negative and start from 0\n",
    "if np.min(y) < 0:\n",
    "    # Shift labels to make them non-negative\n",
    "    y = y - np.min(y)  # This will shift the minimum value to 0\n",
    "print(\"Unique values in y after relabeling:\", np.unique(y))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'min_child_weight': [1, 3],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1],\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier without GPU acceleration\n",
    "xgb_model = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "# Initialize RandomizedSearchCV with fewer iterations and folds\n",
    "xgb_random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,  # Reduced iterations\n",
    "    scoring='accuracy',\n",
    "    cv=2,  # Reduced folds\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the data\n",
    "xgb_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters for XGBoost:\", xgb_random_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", xgb_random_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_xgb_model = xgb_random_search.best_estimator_\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "y_pred_proba = best_xgb_model.predict_proba(X_test)\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report for Tuned XGBoost:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# F1-Score for Class 1\n",
    "f1_class_1 = f1_score(y_test, y_pred, average=None)[1]  # F1-score for class 1\n",
    "print(f\"F1-Score for Class 1: {f1_class_1:.4f}\")\n",
    "\n",
    "# ROC-AUC Score (Multi-Class)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "print(f\"ROC-AUC Score (Multi-Class): {roc_auc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Save the best model for future use\n",
    "joblib.dump(best_xgb_model, 'best_xgb_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text  # Make sure to install this library\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=best_xgb_model.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix for Tuned XGBoost\")\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance Analysis\n",
    "importances = best_xgb_model.feature_importances_\n",
    "feature_names = X.columns  # Assuming X is a DataFrame\n",
    "sorted_indices = np.argsort(importances)\n",
    "\n",
    "# Limit to top N features (e.g., top 10)\n",
    "top_n = 20\n",
    "sorted_indices = sorted_indices[-top_n:]  # Get indices of top N features\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(20, 10))  # Increased figure size\n",
    "plt.barh(range(len(sorted_indices)), importances[sorted_indices], align='center')\n",
    "plt.yticks(range(len(sorted_indices)), feature_names[sorted_indices])\n",
    "\n",
    "# Adding text labels\n",
    "for i, v in enumerate(importances[sorted_indices]):\n",
    "    plt.text(v + 0.01, i, f\"{feature_names[sorted_indices][i]}: {v:.2f}\", va='center')\n",
    "\n",
    "plt.title(\"XGBoost Feature Importance\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model names\n",
    "models = ['Random Forest', 'XGBoost', 'CatBoost']\n",
    "\n",
    "# Accuracy values from your results\n",
    "accuracies = [0.81, 0.86, 0.81]  # Random Forest, XGBoost, and CatBoost accuracies\n",
    "\n",
    "# F1-scores for class 1 from your results\n",
    "f1_scores = [0.72, 0.92, 0.71]  # F1-scores for class 1 for Random Forest, XGBoost, and CatBoost\n",
    "\n",
    "# Create a bar chart for accuracy and F1-score\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Set the bar width\n",
    "bar_width = 0.35\n",
    "x = range(len(models))\n",
    "\n",
    "# Create bars for accuracy\n",
    "plt.bar(x, accuracies, width=bar_width, color='skyblue', alpha=0.7, label='Accuracy')\n",
    "\n",
    "# Create bars for F1-score, offsetting them by the width of the bars\n",
    "plt.bar([p + bar_width for p in x], f1_scores, width=bar_width, color='salmon', alpha=0.7, label='F1-Score for Class 1')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Comparison: Accuracy and F1-Score for Class 1')\n",
    "plt.xticks([p + bar_width / 2 for p in x], models)  # Center the x-tick labels\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)  # Set y-axis limits\n",
    "plt.grid(axis='y')  # Add grid lines for better readability\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Calculate ROC curve and AUC for each model\n",
    "def plot_roc_curve(y_test, y_pred_proba, model_name):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1], pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_roc_curve(y_test, best_xgb_model.predict_proba(X_test), 'XGBoost')\n",
    "# Repeat for other models if you have their predictions\n",
    "# plot_roc_curve(y_test, rf_pred_proba, 'Random Forest')\n",
    "# plot_roc_curve(y_test, catboost_pred_proba, 'CatBoost')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Binarize the output (one-vs-rest) for multi-class Precision-Recall\n",
    "n_classes = len(np.unique(y_test))  # Number of classes\n",
    "y_test_binarized = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "# Calculate Precision-Recall curve and Average Precision for each class\n",
    "precision = {}\n",
    "recall = {}\n",
    "average_precision = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test_binarized[:, i], y_pred_proba[:, i])\n",
    "    average_precision[i] = average_precision_score(y_test_binarized[:, i], y_pred_proba[:, i])\n",
    "\n",
    "# Plot the Precision-Recall curve for each class\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(recall[i], precision[i], lw=2, label=f'Class {i} (AP = {average_precision[i]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve for Multi-Class XGBoost')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPJ8a+Eo6v8dTMIR8/AbFnb",
   "mount_file_id": "1shj_8o1gmhziM_FYENCOyJ_5FPWWsQo7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
